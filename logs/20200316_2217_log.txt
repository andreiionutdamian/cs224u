======================================================================
Running baseline model 'BaseLR_C6L2' with 'concat'
Training model LogisticRegression
              precision    recall  f1-score   support

           0      0.916     0.948     0.932      1910
           1      0.422     0.305     0.354       239

    accuracy                          0.876      2149
   macro avg      0.669     0.627     0.643      2149
weighted avg      0.861     0.876     0.867      2149


Results so far:
         MODEL     SCORE    VECT
0  BaseLR_C6L2  0.642959  concat

======================================================================
Running baseline model 'BaseLR_C4L1' with 'concat'
Training model LogisticRegression
              precision    recall  f1-score   support

           0      0.914     0.968     0.940      1910
           1      0.512     0.272     0.355       239

    accuracy                          0.890      2149
   macro avg      0.713     0.620     0.648      2149
weighted avg      0.869     0.890     0.875      2149


Results so far:
         MODEL     SCORE    VECT
0  BaseLR_C6L2  0.642959  concat
1  BaseLR_C4L1  0.647585  concat

======================================================================
Running baseline model 'BaseNN_50' with 'concat'
Training model TorchShallowNeuralClassifier
Found new best macro-f1 0.5518 > 0.0000 at epoch 1			
Found new best macro-f1 0.6544 > 0.5518 at epoch 2			

Max patience 11/10 reached!
Loading model from epoch 2 with macro-f1 0.6544
              precision    recall  f1-score   support

           0      0.916     0.960     0.938      1910
           1      0.483     0.301     0.371       239

    accuracy                          0.886      2149
   macro avg      0.700     0.630     0.654      2149
weighted avg      0.868     0.886     0.875      2149


Results so far:
         MODEL     SCORE    VECT
0  BaseLR_C6L2  0.642959  concat
1  BaseLR_C4L1  0.647585  concat
2    BaseNN_50  0.654365  concat

======================================================================
Running baseline model 'BaseNN_150' with 'concat'
Training model TorchShallowNeuralClassifier
Found new best macro-f1 0.6234 > 0.0000 at epoch 1			
Found new best macro-f1 0.6408 > 0.6234 at epoch 4			
Found new best macro-f1 0.6487 > 0.6408 at epoch 5			
Found new best macro-f1 0.6570 > 0.6487 at epoch 6			
Found new best macro-f1 0.6574 > 0.6570 at epoch 14			

Max patience 11/10 reached!
Loading model from epoch 14 with macro-f1 0.6574
              precision    recall  f1-score   support

           0      0.924     0.925     0.924      1910
           1      0.392     0.389     0.391       239

    accuracy                          0.865      2149
   macro avg      0.658     0.657     0.657      2149
weighted avg      0.865     0.865     0.865      2149


Results so far:
         MODEL     SCORE    VECT
0  BaseLR_C6L2  0.642959  concat
1  BaseLR_C4L1  0.647585  concat
2    BaseNN_50  0.654365  concat
3   BaseNN_150  0.657440  concat

======================================================================
Running baseline model 'BaseNN_300' with 'concat'
Training model TorchShallowNeuralClassifier
Found new best macro-f1 0.6368 > 0.0000 at epoch 1			
Found new best macro-f1 0.6648 > 0.6368 at epoch 2			
Found new best macro-f1 0.6763 > 0.6648 at epoch 10			

Max patience 11/10 reached!
Loading model from epoch 10 with macro-f1 0.6763
              precision    recall  f1-score   support

           0      0.930     0.919     0.925      1910
           1      0.410     0.448     0.428       239

    accuracy                          0.867      2149
   macro avg      0.670     0.684     0.676      2149
weighted avg      0.872     0.867     0.869      2149


Results so far:
         MODEL     SCORE    VECT
0  BaseLR_C6L2  0.642959  concat
1  BaseLR_C4L1  0.647585  concat
2    BaseNN_50  0.654365  concat
3   BaseNN_150  0.657440  concat
4   BaseNN_300  0.676349  concat

Generated 100 random grid-search iters out of a total of 1728 iters


======================================================================
Running grid search iteration 1/100 'H3_v1_01': {'dual_path': [128], 'layers': [128, 64], 'input_drop': 0, 'other_drop': 0, 'bn': False, 'bn_inputs': False, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: inf hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4747 > 0.0000 at epoch 1			
Found new best macro-f1 0.5297 > 0.4747 at epoch 2			
Found new best macro-f1 0.6116 > 0.5297 at epoch 3			
Found new best macro-f1 0.6185 > 0.6116 at epoch 5			
Found new best macro-f1 0.6416 > 0.6185 at epoch 6			
Found new best macro-f1 0.6496 > 0.6416 at epoch 7			
Found new best macro-f1 0.6568 > 0.6496 at epoch 9			

Max patience 21/20 reached!
Loading model from epoch 9 with macro-f1 0.6568
              precision    recall  f1-score   support

           0      0.917     0.962     0.939      1910
           1      0.497     0.301     0.375       239

    accuracy                          0.888      2149
   macro avg      0.707     0.632     0.657      2149
weighted avg      0.870     0.888     0.876      2149

Results so far:
         MODEL     SCORE    VECT dual_path     layers input_drop other_drop     bn bn_inputs activ     eta
0  BaseLR_C6L2  0.642959  concat                                                                          
1  BaseLR_C4L1  0.647585  concat                                                                          
2    BaseNN_50  0.654365  concat                                                                          
5     H3_v1_01  0.656841  concat     [128]  [128, 64]          0          0  False     False  selu  0.0005
3   BaseNN_150  0.657440  concat                                                                          
4   BaseNN_300  0.676349  concat                                                                          


======================================================================
Running grid search iteration 2/100 'H3_v1_02': {'dual_path': [128, 64], 'layers': [128, 64], 'input_drop': 0, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6013 > 0.0000 at epoch 1			
Found new best macro-f1 0.6060 > 0.6013 at epoch 6			
Found new best macro-f1 0.6140 > 0.6060 at epoch 7			
Found new best macro-f1 0.6144 > 0.6140 at epoch 9			
Found new best macro-f1 0.6200 > 0.6144 at epoch 10			
Found new best macro-f1 0.6258 > 0.6200 at epoch 11			
Found new best macro-f1 0.6385 > 0.6258 at epoch 13			
Found new best macro-f1 0.6388 > 0.6385 at epoch 14			
Found new best macro-f1 0.6424 > 0.6388 at epoch 15			
Found new best macro-f1 0.6505 > 0.6424 at epoch 16			
Found new best macro-f1 0.6514 > 0.6505 at epoch 18			
Found new best macro-f1 0.6555 > 0.6514 at epoch 19			
Found new best macro-f1 0.6626 > 0.6555 at epoch 20			
Found new best macro-f1 0.6715 > 0.6626 at epoch 22			
Found new best macro-f1 0.6745 > 0.6715 at epoch 24			
Found new best macro-f1 0.6775 > 0.6745 at epoch 26			
Found new best macro-f1 0.6786 > 0.6775 at epoch 27			
Found new best macro-f1 0.6823 > 0.6786 at epoch 28			
Found new best macro-f1 0.6878 > 0.6823 at epoch 29			
Found new best macro-f1 0.6952 > 0.6878 at epoch 30			
Found new best macro-f1 0.6962 > 0.6952 at epoch 36			

Max patience 21/20 reached!
Loading model from epoch 36 with macro-f1 0.6962
              precision    recall  f1-score   support

           0      0.936     0.919     0.928      1910
           1      0.436     0.498     0.465       239

    accuracy                          0.872      2149
   macro avg      0.686     0.709     0.696      2149
weighted avg      0.880     0.872     0.876      2149

Results so far:
         MODEL     SCORE    VECT  dual_path     layers input_drop other_drop     bn bn_inputs activ     eta
0  BaseLR_C6L2  0.642959  concat                                                                           
1  BaseLR_C4L1  0.647585  concat                                                                           
2    BaseNN_50  0.654365  concat                                                                           
5     H3_v1_01  0.656841  concat      [128]  [128, 64]          0          0  False     False  selu  0.0005
3   BaseNN_150  0.657440  concat                                                                           
4   BaseNN_300  0.676349  concat                                                                           
6     H3_v1_02  0.696236  concat  [128, 64]  [128, 64]          0        0.5   True      True  tanh  0.0005


======================================================================
Running grid search iteration 3/100 'H3_v1_03': {'dual_path': [128], 'layers': [128, 64], 'input_drop': 0, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.5 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6135 > 0.0000 at epoch 1			
Found new best macro-f1 0.6601 > 0.6135 at epoch 2			
Found new best macro-f1 0.6878 > 0.6601 at epoch 3			
Found new best macro-f1 0.6912 > 0.6878 at epoch 4			

Max patience 21/20 reached!
Loading model from epoch 4 with macro-f1 0.6912
              precision    recall  f1-score   support

           0      0.927     0.949     0.938      1910
           1      0.497     0.402     0.444       239

    accuracy                          0.888      2149
   macro avg      0.712     0.675     0.691      2149
weighted avg      0.879     0.888     0.883      2149

Results so far:
         MODEL     SCORE    VECT  dual_path     layers input_drop other_drop     bn bn_inputs activ     eta
0  BaseLR_C6L2  0.642959  concat                                                                           
1  BaseLR_C4L1  0.647585  concat                                                                           
2    BaseNN_50  0.654365  concat                                                                           
5     H3_v1_01  0.656841  concat      [128]  [128, 64]          0          0  False     False  selu  0.0005
3   BaseNN_150  0.657440  concat                                                                           
4   BaseNN_300  0.676349  concat                                                                           
7     H3_v1_03  0.691182  concat      [128]  [128, 64]          0        0.5   True      True  selu   0.005
6     H3_v1_02  0.696236  concat  [128, 64]  [128, 64]          0        0.5   True      True  tanh  0.0005


======================================================================
Running grid search iteration 4/100 'H3_v1_04': {'dual_path': [128, 64], 'layers': [128, 32], 'input_drop': 0, 'other_drop': 0.5, 'bn': True, 'bn_inputs': False, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.5 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6327 > 0.0000 at epoch 1			
Found new best macro-f1 0.6443 > 0.6327 at epoch 2			
Found new best macro-f1 0.6677 > 0.6443 at epoch 3			
Found new best macro-f1 0.6717 > 0.6677 at epoch 4			

Max patience 21/20 reached!
Loading model from epoch 4 with macro-f1 0.6717
              precision    recall  f1-score   support

           0      0.928     0.925     0.926      1910
           1      0.412     0.423     0.417       239

    accuracy                          0.869      2149
   macro avg      0.670     0.674     0.672      2149
weighted avg      0.870     0.869     0.869      2149

Results so far:
         MODEL     SCORE    VECT  dual_path     layers input_drop other_drop     bn bn_inputs activ     eta
0  BaseLR_C6L2  0.642959  concat                                                                           
1  BaseLR_C4L1  0.647585  concat                                                                           
2    BaseNN_50  0.654365  concat                                                                           
5     H3_v1_01  0.656841  concat      [128]  [128, 64]          0          0  False     False  selu  0.0005
3   BaseNN_150  0.657440  concat                                                                           
8     H3_v1_04  0.671709  concat  [128, 64]  [128, 32]          0        0.5   True     False  selu   0.005
4   BaseNN_300  0.676349  concat                                                                           
7     H3_v1_03  0.691182  concat      [128]  [128, 64]          0        0.5   True      True  selu   0.005
6     H3_v1_02  0.696236  concat  [128, 64]  [128, 64]          0        0.5   True      True  tanh  0.0005


======================================================================
Running grid search iteration 5/100 'H3_v1_05': {'dual_path': [128, 64], 'layers': [128, 64], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': False, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.0005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5811 > 0.4706 at epoch 10			
Found new best macro-f1 0.6212 > 0.5811 at epoch 11			
Found new best macro-f1 0.6752 > 0.6212 at epoch 12			
Found new best macro-f1 0.6947 > 0.6752 at epoch 13			
Found new best macro-f1 0.7062 > 0.6947 at epoch 14			

Max patience 21/20 reached!
Loading model from epoch 14 with macro-f1 0.7062
              precision    recall  f1-score   support

           0      0.927     0.962     0.945      1910
           1      0.569     0.397     0.468       239

    accuracy                          0.899      2149
   macro avg      0.748     0.680     0.706      2149
weighted avg      0.887     0.899     0.892      2149

Results so far:
         MODEL     SCORE    VECT  dual_path     layers input_drop other_drop     bn bn_inputs activ     eta
0  BaseLR_C6L2  0.642959  concat                                                                           
1  BaseLR_C4L1  0.647585  concat                                                                           
2    BaseNN_50  0.654365  concat                                                                           
5     H3_v1_01  0.656841  concat      [128]  [128, 64]          0          0  False     False  selu  0.0005
3   BaseNN_150  0.657440  concat                                                                           
8     H3_v1_04  0.671709  concat  [128, 64]  [128, 32]          0        0.5   True     False  selu   0.005
4   BaseNN_300  0.676349  concat                                                                           
7     H3_v1_03  0.691182  concat      [128]  [128, 64]          0        0.5   True      True  selu   0.005
6     H3_v1_02  0.696236  concat  [128, 64]  [128, 64]          0        0.5   True      True  tanh  0.0005
9     H3_v1_05  0.706241  concat  [128, 64]  [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 6/100 'H3_v1_06': {'dual_path': [128], 'layers': [64], 'input_drop': 0, 'other_drop': 0.5, 'bn': False, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4972 > 0.0000 at epoch 1			
Found new best macro-f1 0.5021 > 0.4972 at epoch 2			
Found new best macro-f1 0.5160 > 0.5021 at epoch 3			
Found new best macro-f1 0.5720 > 0.5160 at epoch 4			
Found new best macro-f1 0.6192 > 0.5720 at epoch 5			
Found new best macro-f1 0.6311 > 0.6192 at epoch 6			
Found new best macro-f1 0.6342 > 0.6311 at epoch 7			
Found new best macro-f1 0.6347 > 0.6342 at epoch 8			
Found new best macro-f1 0.6379 > 0.6347 at epoch 9			
Found new best macro-f1 0.6454 > 0.6379 at epoch 10			
Found new best macro-f1 0.6509 > 0.6454 at epoch 21			
Found new best macro-f1 0.6514 > 0.6509 at epoch 24			
Found new best macro-f1 0.6536 > 0.6514 at epoch 30			

Max patience 21/20 reached!
Loading model from epoch 30 with macro-f1 0.6536
              precision    recall  f1-score   support

           0      0.915     0.969     0.941      1910
           1      0.528     0.280     0.366       239

    accuracy                          0.892      2149
   macro avg      0.721     0.624     0.654      2149
weighted avg      0.872     0.892     0.877      2149

Results so far:
          MODEL     SCORE    VECT  dual_path     layers input_drop other_drop     bn bn_inputs activ     eta
0   BaseLR_C6L2  0.642959  concat                                                                           
1   BaseLR_C4L1  0.647585  concat                                                                           
10     H3_v1_06  0.653559  concat      [128]       [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                           
5      H3_v1_01  0.656841  concat      [128]  [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                           
8      H3_v1_04  0.671709  concat  [128, 64]  [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                           
7      H3_v1_03  0.691182  concat      [128]  [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]  [128, 64]          0        0.5   True      True  tanh  0.0005
9      H3_v1_05  0.706241  concat  [128, 64]  [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 7/100 'H3_v1_07': {'dual_path': None, 'layers': [128, 64], 'input_drop': 0, 'other_drop': 0, 'bn': False, 'bn_inputs': False, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5039 > 0.0000 at epoch 1			
Found new best macro-f1 0.5322 > 0.5039 at epoch 2			
Found new best macro-f1 0.6089 > 0.5322 at epoch 3			
Found new best macro-f1 0.6514 > 0.6089 at epoch 4			
Found new best macro-f1 0.6581 > 0.6514 at epoch 5			

Max patience 21/20 reached!
Loading model from epoch 5 with macro-f1 0.6581
              precision    recall  f1-score   support

           0      0.917     0.963     0.939      1910
           1      0.503     0.301     0.377       239

    accuracy                          0.889      2149
   macro avg      0.710     0.632     0.658      2149
weighted avg      0.871     0.889     0.877      2149

Results so far:
          MODEL     SCORE    VECT  dual_path     layers input_drop other_drop     bn bn_inputs activ     eta
0   BaseLR_C6L2  0.642959  concat                                                                           
1   BaseLR_C4L1  0.647585  concat                                                                           
10     H3_v1_06  0.653559  concat      [128]       [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                           
5      H3_v1_01  0.656841  concat      [128]  [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                           
11     H3_v1_07  0.658094  concat       None  [128, 64]          0          0  False     False  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]  [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                           
7      H3_v1_03  0.691182  concat      [128]  [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]  [128, 64]          0        0.5   True      True  tanh  0.0005
9      H3_v1_05  0.706241  concat  [128, 64]  [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 8/100 'H3_v1_08': {'dual_path': [128], 'layers': [256, 128, 64], 'input_drop': 0.3, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6271 > 0.0000 at epoch 1			
Found new best macro-f1 0.6575 > 0.6271 at epoch 2			
Found new best macro-f1 0.6790 > 0.6575 at epoch 3			
Found new best macro-f1 0.6883 > 0.6790 at epoch 6			

Max patience 21/20 reached!
Loading model from epoch 6 with macro-f1 0.6883
              precision    recall  f1-score   support

           0      0.930     0.935     0.932      1910
           1      0.454     0.435     0.444       239

    accuracy                          0.879      2149
   macro avg      0.692     0.685     0.688      2149
weighted avg      0.877     0.879     0.878      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 9/100 'H3_v1_09': {'dual_path': [128], 'layers': [64], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': True, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6630 > 0.0000 at epoch 1			
Found new best macro-f1 0.6964 > 0.6630 at epoch 2			

Max patience 21/20 reached!
Loading model from epoch 2 with macro-f1 0.6964
              precision    recall  f1-score   support

           0      0.930     0.941     0.936      1910
           1      0.481     0.435     0.457       239

    accuracy                          0.885      2149
   macro avg      0.706     0.688     0.696      2149
weighted avg      0.880     0.885     0.883      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 10/100 'H3_v1_10': {'dual_path': [128], 'layers': [256, 128, 64], 'input_drop': 0, 'other_drop': 0.3, 'bn': False, 'bn_inputs': False, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.6820 > 0.4706 at epoch 4			
Found new best macro-f1 0.6888 > 0.6820 at epoch 7			

Max patience 21/20 reached!
Loading model from epoch 7 with macro-f1 0.6888
              precision    recall  f1-score   support

           0      0.930     0.934     0.932      1910
           1      0.453     0.439     0.446       239

    accuracy                          0.879      2149
   macro avg      0.691     0.686     0.689      2149
weighted avg      0.877     0.879     0.878      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 11/100 'H3_v1_11': {'dual_path': [128, 64], 'layers': [64], 'input_drop': 0, 'other_drop': 0.3, 'bn': False, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4704 > 0.0000 at epoch 1			
Found new best macro-f1 0.4912 > 0.4704 at epoch 3			
Found new best macro-f1 0.5500 > 0.4912 at epoch 4			
Found new best macro-f1 0.5982 > 0.5500 at epoch 5			
Found new best macro-f1 0.6367 > 0.5982 at epoch 6			
Found new best macro-f1 0.6386 > 0.6367 at epoch 7			
Found new best macro-f1 0.6410 > 0.6386 at epoch 8			
Found new best macro-f1 0.6428 > 0.6410 at epoch 9			
Found new best macro-f1 0.6446 > 0.6428 at epoch 12			
Found new best macro-f1 0.6507 > 0.6446 at epoch 15			

Max patience 21/20 reached!
Loading model from epoch 15 with macro-f1 0.6507
              precision    recall  f1-score   support

           0      0.915     0.962     0.938      1910
           1      0.489     0.289     0.363       239

    accuracy                          0.887      2149
   macro avg      0.702     0.626     0.651      2149
weighted avg      0.868     0.887     0.874      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 12/100 'H3_v1_12': {'dual_path': [128, 64], 'layers': [128, 64], 'input_drop': 0, 'other_drop': 0, 'bn': False, 'bn_inputs': False, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5598 > 0.4706 at epoch 3			
Found new best macro-f1 0.6557 > 0.5598 at epoch 4			
Found new best macro-f1 0.6651 > 0.6557 at epoch 5			
Found new best macro-f1 0.6889 > 0.6651 at epoch 6			

Max patience 21/20 reached!
Loading model from epoch 6 with macro-f1 0.6889
              precision    recall  f1-score   support

           0      0.930     0.935     0.932      1910
           1      0.456     0.435     0.445       239

    accuracy                          0.879      2149
   macro avg      0.693     0.685     0.689      2149
weighted avg      0.877     0.879     0.878      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 13/100 'H3_v1_13': {'dual_path': None, 'layers': [64], 'input_drop': 0, 'other_drop': 0.5, 'bn': True, 'bn_inputs': False, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5104 > 0.0000 at epoch 1			
Found new best macro-f1 0.6106 > 0.5104 at epoch 2			
Found new best macro-f1 0.6559 > 0.6106 at epoch 3			
Found new best macro-f1 0.6641 > 0.6559 at epoch 5			
Found new best macro-f1 0.6737 > 0.6641 at epoch 11			
Found new best macro-f1 0.6771 > 0.6737 at epoch 31			

Max patience 21/20 reached!
Loading model from epoch 31 with macro-f1 0.6771
              precision    recall  f1-score   support

           0      0.922     0.955     0.939      1910
           1      0.500     0.356     0.416       239

    accuracy                          0.889      2149
   macro avg      0.711     0.656     0.677      2149
weighted avg      0.875     0.889     0.880      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 14/100 'H3_v1_14': {'dual_path': None, 'layers': [64], 'input_drop': 0.3, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6106 > 0.0000 at epoch 1			
Found new best macro-f1 0.6398 > 0.6106 at epoch 2			
Found new best macro-f1 0.6399 > 0.6398 at epoch 4			
Found new best macro-f1 0.6482 > 0.6399 at epoch 9			
Found new best macro-f1 0.6523 > 0.6482 at epoch 12			
Found new best macro-f1 0.6541 > 0.6523 at epoch 13			
Found new best macro-f1 0.6689 > 0.6541 at epoch 14			
Found new best macro-f1 0.6710 > 0.6689 at epoch 15			
Found new best macro-f1 0.6834 > 0.6710 at epoch 16			
Found new best macro-f1 0.6875 > 0.6834 at epoch 19			
Found new best macro-f1 0.6879 > 0.6875 at epoch 23			
Found new best macro-f1 0.6892 > 0.6879 at epoch 24			

Max patience 21/20 reached!
Loading model from epoch 24 with macro-f1 0.6892
              precision    recall  f1-score   support

           0      0.928     0.945     0.936      1910
           1      0.480     0.410     0.442       239

    accuracy                          0.885      2149
   macro avg      0.704     0.677     0.689      2149
weighted avg      0.878     0.885     0.881      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 15/100 'H3_v1_15': {'dual_path': None, 'layers': [128, 32], 'input_drop': 0, 'other_drop': 0.5, 'bn': False, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.6254 > 0.4706 at epoch 2			
Found new best macro-f1 0.6374 > 0.6254 at epoch 3			
Found new best macro-f1 0.6626 > 0.6374 at epoch 4			
Found new best macro-f1 0.6659 > 0.6626 at epoch 8			
Found new best macro-f1 0.6725 > 0.6659 at epoch 12			
Found new best macro-f1 0.6805 > 0.6725 at epoch 16			
Found new best macro-f1 0.6886 > 0.6805 at epoch 19			
Found new best macro-f1 0.6897 > 0.6886 at epoch 38			

Max patience 21/20 reached!
Loading model from epoch 38 with macro-f1 0.6897
              precision    recall  f1-score   support

           0      0.929     0.940     0.934      1910
           1      0.470     0.423     0.445       239

    accuracy                          0.883      2149
   macro avg      0.699     0.681     0.690      2149
weighted avg      0.878     0.883     0.880      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 16/100 'H3_v1_16': {'dual_path': None, 'layers': [64], 'input_drop': 0, 'other_drop': 0, 'bn': True, 'bn_inputs': False, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6199 > 0.0000 at epoch 1			
Found new best macro-f1 0.6478 > 0.6199 at epoch 2			
Found new best macro-f1 0.6590 > 0.6478 at epoch 4			
Found new best macro-f1 0.6598 > 0.6590 at epoch 11			
Found new best macro-f1 0.6716 > 0.6598 at epoch 22			

Max patience 21/20 reached!
Loading model from epoch 22 with macro-f1 0.6716
              precision    recall  f1-score   support

           0      0.924     0.941     0.932      1910
           1      0.446     0.381     0.411       239

    accuracy                          0.879      2149
   macro avg      0.685     0.661     0.672      2149
weighted avg      0.871     0.879     0.874      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 17/100 'H3_v1_17': {'dual_path': None, 'layers': [128, 32], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': True, 'bn_inputs': True, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6221 > 0.0000 at epoch 1			
Found new best macro-f1 0.6335 > 0.6221 at epoch 7			
Found new best macro-f1 0.6430 > 0.6335 at epoch 8			
Found new best macro-f1 0.6524 > 0.6430 at epoch 9			
Found new best macro-f1 0.6594 > 0.6524 at epoch 10			
Found new best macro-f1 0.6697 > 0.6594 at epoch 13			
Found new best macro-f1 0.6729 > 0.6697 at epoch 24			
Found new best macro-f1 0.6729 > 0.6729 at epoch 25			
Found new best macro-f1 0.6743 > 0.6729 at epoch 26			
Found new best macro-f1 0.6756 > 0.6743 at epoch 27			
Found new best macro-f1 0.6781 > 0.6756 at epoch 30			

Max patience 21/20 reached!
Loading model from epoch 30 with macro-f1 0.6781
              precision    recall  f1-score   support

           0      0.923     0.951     0.937      1910
           1      0.486     0.368     0.419       239

    accuracy                          0.886      2149
   macro avg      0.705     0.660     0.678      2149
weighted avg      0.875     0.886     0.879      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 18/100 'H3_v1_18': {'dual_path': [128, 64], 'layers': [128, 32], 'input_drop': 0, 'other_drop': 0.5, 'bn': False, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5280 > 0.0000 at epoch 1			
Found new best macro-f1 0.5282 > 0.5280 at epoch 4			
Found new best macro-f1 0.5650 > 0.5282 at epoch 5			
Found new best macro-f1 0.5943 > 0.5650 at epoch 6			
Found new best macro-f1 0.6008 > 0.5943 at epoch 8			
Found new best macro-f1 0.6034 > 0.6008 at epoch 9			
Found new best macro-f1 0.6158 > 0.6034 at epoch 10			
Found new best macro-f1 0.6239 > 0.6158 at epoch 11			
Found new best macro-f1 0.6256 > 0.6239 at epoch 13			
Found new best macro-f1 0.6269 > 0.6256 at epoch 14			
Found new best macro-f1 0.6277 > 0.6269 at epoch 15			
Found new best macro-f1 0.6312 > 0.6277 at epoch 18			
Found new best macro-f1 0.6356 > 0.6312 at epoch 19			
Found new best macro-f1 0.6380 > 0.6356 at epoch 21			
Found new best macro-f1 0.6390 > 0.6380 at epoch 30			
Found new best macro-f1 0.6414 > 0.6390 at epoch 41			

Max patience 21/20 reached!
Loading model from epoch 41 with macro-f1 0.6414
              precision    recall  f1-score   support

           0      0.914     0.958     0.936      1910
           1      0.456     0.280     0.347       239

    accuracy                          0.883      2149
   macro avg      0.685     0.619     0.641      2149
weighted avg      0.863     0.883     0.870      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 19/100 'H3_v1_19': {'dual_path': [128, 64], 'layers': [128, 64], 'input_drop': 0, 'other_drop': 0.3, 'bn': False, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5920 > 0.4706 at epoch 3			
Found new best macro-f1 0.6045 > 0.5920 at epoch 4			
Found new best macro-f1 0.6767 > 0.6045 at epoch 5			
Found new best macro-f1 0.6768 > 0.6767 at epoch 7			
Found new best macro-f1 0.6825 > 0.6768 at epoch 9			
Found new best macro-f1 0.6839 > 0.6825 at epoch 11			

Max patience 21/20 reached!
Loading model from epoch 11 with macro-f1 0.6839
              precision    recall  f1-score   support

           0      0.924     0.956     0.940      1910
           1      0.512     0.368     0.428       239

    accuracy                          0.891      2149
   macro avg      0.718     0.662     0.684      2149
weighted avg      0.878     0.891     0.883      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 20/100 'H3_v1_20': {'dual_path': [128, 64], 'layers': [128, 32], 'input_drop': 0, 'other_drop': 0.5, 'bn': False, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4789 > 0.0000 at epoch 1			
Found new best macro-f1 0.5762 > 0.4789 at epoch 2			
Found new best macro-f1 0.5925 > 0.5762 at epoch 3			
Found new best macro-f1 0.6135 > 0.5925 at epoch 4			
Found new best macro-f1 0.6139 > 0.6135 at epoch 5			
Found new best macro-f1 0.6153 > 0.6139 at epoch 22			
Found new best macro-f1 0.6283 > 0.6153 at epoch 28			
Found new best macro-f1 0.6317 > 0.6283 at epoch 45			
Found new best macro-f1 0.6356 > 0.6317 at epoch 64			

Max patience 21/20 reached!
Loading model from epoch 64 with macro-f1 0.6356
              precision    recall  f1-score   support

           0      0.921     0.910     0.915      1910
           1      0.341     0.372     0.356       239

    accuracy                          0.850      2149
   macro avg      0.631     0.641     0.636      2149
weighted avg      0.856     0.850     0.853      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005


======================================================================
Running grid search iteration 21/100 'H3_v1_21': {'dual_path': None, 'layers': [128, 32], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': False, 'bn_inputs': False, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5333 > 0.4706 at epoch 2			
Found new best macro-f1 0.6039 > 0.5333 at epoch 3			
Found new best macro-f1 0.6754 > 0.6039 at epoch 4			
Found new best macro-f1 0.6759 > 0.6754 at epoch 5			
Found new best macro-f1 0.6961 > 0.6759 at epoch 8			
Found new best macro-f1 0.7247 > 0.6961 at epoch 9			
Found new best macro-f1 0.7282 > 0.7247 at epoch 12			

Max patience 21/20 reached!
Loading model from epoch 12 with macro-f1 0.7282
              precision    recall  f1-score   support

           0      0.933     0.961     0.947      1910
           1      0.591     0.448     0.510       239

    accuracy                          0.904      2149
   macro avg      0.762     0.704     0.728      2149
weighted avg      0.895     0.904     0.898      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 22/100 'H3_v1_22': {'dual_path': None, 'layers': [64], 'input_drop': 0.3, 'other_drop': 0, 'bn': True, 'bn_inputs': False, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4375 > 0.0000 at epoch 1			
Found new best macro-f1 0.5013 > 0.4375 at epoch 2			
Found new best macro-f1 0.5210 > 0.5013 at epoch 3			
Found new best macro-f1 0.5510 > 0.5210 at epoch 4			
Found new best macro-f1 0.5567 > 0.5510 at epoch 5			
Found new best macro-f1 0.5748 > 0.5567 at epoch 7			
Found new best macro-f1 0.6009 > 0.5748 at epoch 8			
Found new best macro-f1 0.6128 > 0.6009 at epoch 10			
Found new best macro-f1 0.6416 > 0.6128 at epoch 11			
Found new best macro-f1 0.6556 > 0.6416 at epoch 13			
Found new best macro-f1 0.6730 > 0.6556 at epoch 14			

Max patience 21/20 reached!
Loading model from epoch 14 with macro-f1 0.6730
              precision    recall  f1-score   support

           0      0.935     0.895     0.915      1910
           1      0.376     0.506     0.431       239

    accuracy                          0.852      2149
   macro avg      0.656     0.701     0.673      2149
weighted avg      0.873     0.852     0.861      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 23/100 'H3_v1_23': {'dual_path': [128, 64], 'layers': [256, 128, 64], 'input_drop': 0, 'other_drop': 0.3, 'bn': False, 'bn_inputs': False, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.4833 > 0.4706 at epoch 4			
Found new best macro-f1 0.6410 > 0.4833 at epoch 5			
Found new best macro-f1 0.6622 > 0.6410 at epoch 6			
Found new best macro-f1 0.6859 > 0.6622 at epoch 7			

Max patience 21/20 reached!
Loading model from epoch 7 with macro-f1 0.6859
              precision    recall  f1-score   support

           0      0.924     0.954     0.939      1910
           1      0.508     0.377     0.433       239

    accuracy                          0.890      2149
   macro avg      0.716     0.666     0.686      2149
weighted avg      0.878     0.890     0.883      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 24/100 'H3_v1_24': {'dual_path': [128], 'layers': [256, 128, 64], 'input_drop': 0, 'other_drop': 0, 'bn': False, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5493 > 0.0000 at epoch 1			
Found new best macro-f1 0.5822 > 0.5493 at epoch 2			
Found new best macro-f1 0.6045 > 0.5822 at epoch 3			
Found new best macro-f1 0.6551 > 0.6045 at epoch 6			

Max patience 21/20 reached!
Loading model from epoch 6 with macro-f1 0.6551
              precision    recall  f1-score   support

           0      0.920     0.938     0.929      1910
           1      0.416     0.351     0.381       239

    accuracy                          0.873      2149
   macro avg      0.668     0.645     0.655      2149
weighted avg      0.864     0.873     0.868      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 25/100 'H3_v1_25': {'dual_path': None, 'layers': [256, 128, 64], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': False, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.6017 > 0.4706 at epoch 2			
Found new best macro-f1 0.6293 > 0.6017 at epoch 3			
Found new best macro-f1 0.6885 > 0.6293 at epoch 4			
Found new best macro-f1 0.6991 > 0.6885 at epoch 10			
Found new best macro-f1 0.7062 > 0.6991 at epoch 19			
Found new best macro-f1 0.7063 > 0.7062 at epoch 33			

Max patience 21/20 reached!
Loading model from epoch 33 with macro-f1 0.7063
              precision    recall  f1-score   support

           0      0.938     0.923     0.930      1910
           1      0.454     0.515     0.482       239

    accuracy                          0.877      2149
   macro avg      0.696     0.719     0.706      2149
weighted avg      0.884     0.877     0.880      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 26/100 'H3_v1_26': {'dual_path': [128], 'layers': [256, 128, 64], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': False, 'bn_inputs': True, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5701 > 0.4706 at epoch 2			
Found new best macro-f1 0.6112 > 0.5701 at epoch 4			
Found new best macro-f1 0.6204 > 0.6112 at epoch 8			
Found new best macro-f1 0.6306 > 0.6204 at epoch 10			
Found new best macro-f1 0.6341 > 0.6306 at epoch 12			
Found new best macro-f1 0.6367 > 0.6341 at epoch 22			
Found new best macro-f1 0.6386 > 0.6367 at epoch 24			
Found new best macro-f1 0.6439 > 0.6386 at epoch 33			
Found new best macro-f1 0.6502 > 0.6439 at epoch 34			
Found new best macro-f1 0.6517 > 0.6502 at epoch 53			

Max patience 21/20 reached!
Loading model from epoch 53 with macro-f1 0.6517
              precision    recall  f1-score   support

           0      0.915     0.967     0.940      1910
           1      0.515     0.280     0.363       239

    accuracy                          0.891      2149
   macro avg      0.715     0.624     0.652      2149
weighted avg      0.870     0.891     0.876      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 27/100 'H3_v1_27': {'dual_path': None, 'layers': [128, 32], 'input_drop': 0, 'other_drop': 0.3, 'bn': False, 'bn_inputs': False, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5063 > 0.0000 at epoch 1			
Found new best macro-f1 0.5197 > 0.5063 at epoch 2			
Found new best macro-f1 0.5913 > 0.5197 at epoch 3			
Found new best macro-f1 0.6156 > 0.5913 at epoch 4			
Found new best macro-f1 0.6234 > 0.6156 at epoch 5			
Found new best macro-f1 0.6380 > 0.6234 at epoch 6			
Found new best macro-f1 0.6529 > 0.6380 at epoch 9			

Max patience 21/20 reached!
Loading model from epoch 9 with macro-f1 0.6529
              precision    recall  f1-score   support

           0      0.915     0.968     0.941      1910
           1      0.523     0.280     0.365       239

    accuracy                          0.892      2149
   macro avg      0.719     0.624     0.653      2149
weighted avg      0.871     0.892     0.877      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 28/100 'H3_v1_28': {'dual_path': None, 'layers': [64], 'input_drop': 0, 'other_drop': 0, 'bn': True, 'bn_inputs': False, 'activ': 'relu', 'eta': 0.0005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6113 > 0.0000 at epoch 1			
Found new best macro-f1 0.6742 > 0.6113 at epoch 2			
Found new best macro-f1 0.6781 > 0.6742 at epoch 3			

Max patience 21/20 reached!
Loading model from epoch 3 with macro-f1 0.6781
              precision    recall  f1-score   support

           0      0.922     0.960     0.940      1910
           1      0.519     0.347     0.416       239

    accuracy                          0.892      2149
   macro avg      0.720     0.653     0.678      2149
weighted avg      0.877     0.892     0.882      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 29/100 'H3_v1_29': {'dual_path': [128, 64], 'layers': [128, 64], 'input_drop': 0, 'other_drop': 0.3, 'bn': False, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4788 > 0.0000 at epoch 1			
Found new best macro-f1 0.5285 > 0.4788 at epoch 2			
Found new best macro-f1 0.6032 > 0.5285 at epoch 3			
Found new best macro-f1 0.6299 > 0.6032 at epoch 4			
Found new best macro-f1 0.6313 > 0.6299 at epoch 5			
Found new best macro-f1 0.6548 > 0.6313 at epoch 6			
Found new best macro-f1 0.6557 > 0.6548 at epoch 7			
Found new best macro-f1 0.6651 > 0.6557 at epoch 12			

Max patience 21/20 reached!
Loading model from epoch 12 with macro-f1 0.6651
              precision    recall  f1-score   support

           0      0.918     0.965     0.941      1910
           1      0.525     0.310     0.389       239

    accuracy                          0.892      2149
   macro avg      0.721     0.637     0.665      2149
weighted avg      0.874     0.892     0.879      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 30/100 'H3_v1_30': {'dual_path': [128], 'layers': [128, 64], 'input_drop': 0, 'other_drop': 0.3, 'bn': True, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6089 > 0.0000 at epoch 1			
Found new best macro-f1 0.6372 > 0.6089 at epoch 2			
Found new best macro-f1 0.6473 > 0.6372 at epoch 3			
Found new best macro-f1 0.6526 > 0.6473 at epoch 4			
Found new best macro-f1 0.6799 > 0.6526 at epoch 5			
Found new best macro-f1 0.6801 > 0.6799 at epoch 13			
Found new best macro-f1 0.6919 > 0.6801 at epoch 19			
Found new best macro-f1 0.7022 > 0.6919 at epoch 22			
Found new best macro-f1 0.7024 > 0.7022 at epoch 27			

Max patience 21/20 reached!
Loading model from epoch 27 with macro-f1 0.7024
              precision    recall  f1-score   support

           0      0.942     0.907     0.924      1910
           1      0.426     0.552     0.481       239

    accuracy                          0.867      2149
   macro avg      0.684     0.730     0.702      2149
weighted avg      0.884     0.867     0.875      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 31/100 'H3_v1_31': {'dual_path': [128], 'layers': [64], 'input_drop': 0.3, 'other_drop': 0, 'bn': True, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6168 > 0.0000 at epoch 1			
Found new best macro-f1 0.6590 > 0.6168 at epoch 2			
Found new best macro-f1 0.6734 > 0.6590 at epoch 10			
Found new best macro-f1 0.6799 > 0.6734 at epoch 12			
Found new best macro-f1 0.6903 > 0.6799 at epoch 26			
Found new best macro-f1 0.7068 > 0.6903 at epoch 32			

Max patience 21/20 reached!
Loading model from epoch 32 with macro-f1 0.7068
              precision    recall  f1-score   support

           0      0.931     0.948     0.940      1910
           1      0.515     0.439     0.474       239

    accuracy                          0.892      2149
   macro avg      0.723     0.694     0.707      2149
weighted avg      0.885     0.892     0.888      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 32/100 'H3_v1_32': {'dual_path': None, 'layers': [64], 'input_drop': 0, 'other_drop': 0.5, 'bn': False, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5892 > 0.0000 at epoch 1			
Found new best macro-f1 0.5932 > 0.5892 at epoch 3			
Found new best macro-f1 0.6263 > 0.5932 at epoch 4			
Found new best macro-f1 0.6334 > 0.6263 at epoch 6			
Found new best macro-f1 0.6397 > 0.6334 at epoch 8			
Found new best macro-f1 0.6487 > 0.6397 at epoch 11			
Found new best macro-f1 0.6500 > 0.6487 at epoch 18			
Found new best macro-f1 0.6505 > 0.6500 at epoch 22			
Found new best macro-f1 0.6514 > 0.6505 at epoch 24			
Found new best macro-f1 0.6539 > 0.6514 at epoch 33			
Found new best macro-f1 0.6562 > 0.6539 at epoch 36			
Found new best macro-f1 0.6700 > 0.6562 at epoch 47			
Found new best macro-f1 0.6705 > 0.6700 at epoch 67			
Found new best macro-f1 0.6707 > 0.6705 at epoch 80			
Found new best macro-f1 0.6728 > 0.6707 at epoch 84			
Found new best macro-f1 0.6779 > 0.6728 at epoch 86			

Max patience 21/20 reached!
Loading model from epoch 86 with macro-f1 0.6779
              precision    recall  f1-score   support

           0      0.926     0.940     0.933      1910
           1      0.452     0.397     0.423       239

    accuracy                          0.879      2149
   macro avg      0.689     0.669     0.678      2149
weighted avg      0.873     0.879     0.876      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 33/100 'H3_v1_33': {'dual_path': None, 'layers': [256, 128, 64], 'input_drop': 0, 'other_drop': 0.3, 'bn': True, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5856 > 0.0000 at epoch 1			
Found new best macro-f1 0.5912 > 0.5856 at epoch 6			
Found new best macro-f1 0.5948 > 0.5912 at epoch 8			
Found new best macro-f1 0.6022 > 0.5948 at epoch 10			
Found new best macro-f1 0.6069 > 0.6022 at epoch 11			
Found new best macro-f1 0.6088 > 0.6069 at epoch 12			
Found new best macro-f1 0.6168 > 0.6088 at epoch 13			
Found new best macro-f1 0.6253 > 0.6168 at epoch 14			
Found new best macro-f1 0.6285 > 0.6253 at epoch 15			
Found new best macro-f1 0.6290 > 0.6285 at epoch 16			
Found new best macro-f1 0.6353 > 0.6290 at epoch 17			
Found new best macro-f1 0.6492 > 0.6353 at epoch 18			
Found new best macro-f1 0.6612 > 0.6492 at epoch 19			
Found new best macro-f1 0.6614 > 0.6612 at epoch 30			

Max patience 21/20 reached!
Loading model from epoch 30 with macro-f1 0.6614
              precision    recall  f1-score   support

           0      0.923     0.934     0.928      1910
           1      0.415     0.377     0.395       239

    accuracy                          0.872      2149
   macro avg      0.669     0.655     0.661      2149
weighted avg      0.866     0.872     0.869      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 34/100 'H3_v1_34': {'dual_path': [128, 64], 'layers': [64], 'input_drop': 0.3, 'other_drop': 0, 'bn': False, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5828 > 0.0000 at epoch 1			
Found new best macro-f1 0.6054 > 0.5828 at epoch 2			
Found new best macro-f1 0.6086 > 0.6054 at epoch 3			
Found new best macro-f1 0.6197 > 0.6086 at epoch 4			
Found new best macro-f1 0.6260 > 0.6197 at epoch 8			
Found new best macro-f1 0.6478 > 0.6260 at epoch 12			
Found new best macro-f1 0.6848 > 0.6478 at epoch 14			

Max patience 21/20 reached!
Loading model from epoch 14 with macro-f1 0.6848
              precision    recall  f1-score   support

           0      0.926     0.946     0.936      1910
           1      0.477     0.397     0.434       239

    accuracy                          0.885      2149
   macro avg      0.702     0.672     0.685      2149
weighted avg      0.876     0.885     0.880      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 35/100 'H3_v1_35': {'dual_path': [128], 'layers': [128, 32], 'input_drop': 0, 'other_drop': 0.5, 'bn': False, 'bn_inputs': False, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.4 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6291 > 0.0000 at epoch 1			
Found new best macro-f1 0.6295 > 0.6291 at epoch 9			

Max patience 21/20 reached!
Loading model from epoch 9 with macro-f1 0.6295
              precision    recall  f1-score   support

           0      0.913     0.947     0.930      1910
           1      0.399     0.280     0.329       239

    accuracy                          0.873      2149
   macro avg      0.656     0.614     0.630      2149
weighted avg      0.856     0.873     0.863      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 36/100 'H3_v1_36': {'dual_path': [128, 64], 'layers': [128, 32], 'input_drop': 0, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.0005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.1001 > 0.0000 at epoch 1			
Found new best macro-f1 0.1336 > 0.1001 at epoch 4			
Found new best macro-f1 0.3103 > 0.1336 at epoch 5			
Found new best macro-f1 0.4595 > 0.3103 at epoch 6			
Found new best macro-f1 0.5523 > 0.4595 at epoch 7			
Found new best macro-f1 0.6152 > 0.5523 at epoch 8			
Found new best macro-f1 0.6467 > 0.6152 at epoch 9			
Found new best macro-f1 0.6535 > 0.6467 at epoch 12			
Found new best macro-f1 0.6572 > 0.6535 at epoch 13			
Found new best macro-f1 0.6582 > 0.6572 at epoch 16			
Found new best macro-f1 0.6631 > 0.6582 at epoch 17			
Found new best macro-f1 0.6667 > 0.6631 at epoch 18			
Found new best macro-f1 0.6691 > 0.6667 at epoch 19			
Found new best macro-f1 0.6739 > 0.6691 at epoch 20			
Found new best macro-f1 0.6854 > 0.6739 at epoch 21			
Found new best macro-f1 0.6860 > 0.6854 at epoch 30			
Found new best macro-f1 0.6860 > 0.6860 at epoch 33			
Found new best macro-f1 0.6912 > 0.6860 at epoch 38			
Found new best macro-f1 0.6996 > 0.6912 at epoch 40			
Found new best macro-f1 0.7000 > 0.6996 at epoch 41			
Found new best macro-f1 0.7018 > 0.7000 at epoch 43			

Max patience 21/20 reached!
Loading model from epoch 43 with macro-f1 0.7018
              precision    recall  f1-score   support

           0      0.930     0.947     0.939      1910
           1      0.505     0.431     0.465       239

    accuracy                          0.890      2149
   macro avg      0.717     0.689     0.702      2149
weighted avg      0.883     0.890     0.886      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 37/100 'H3_v1_37': {'dual_path': [128, 64], 'layers': [128, 32], 'input_drop': 0, 'other_drop': 0.3, 'bn': True, 'bn_inputs': False, 'activ': 'relu', 'eta': 0.0005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5018 > 0.4706 at epoch 4			
Found new best macro-f1 0.6183 > 0.5018 at epoch 5			
Found new best macro-f1 0.6368 > 0.6183 at epoch 6			
Found new best macro-f1 0.6462 > 0.6368 at epoch 7			
Found new best macro-f1 0.6511 > 0.6462 at epoch 9			
Found new best macro-f1 0.6534 > 0.6511 at epoch 25			

Max patience 21/20 reached!
Loading model from epoch 25 with macro-f1 0.6534
              precision    recall  f1-score   support

           0      0.920     0.940     0.930      1910
           1      0.418     0.343     0.377       239

    accuracy                          0.874      2149
   macro avg      0.669     0.642     0.653      2149
weighted avg      0.864     0.874     0.868      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 38/100 'H3_v1_38': {'dual_path': [128, 64], 'layers': [128, 32], 'input_drop': 0.3, 'other_drop': 0, 'bn': False, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5495 > 0.4706 at epoch 2			
Found new best macro-f1 0.5869 > 0.5495 at epoch 3			
Found new best macro-f1 0.6243 > 0.5869 at epoch 4			
Found new best macro-f1 0.6264 > 0.6243 at epoch 5			
Found new best macro-f1 0.6366 > 0.6264 at epoch 8			
Found new best macro-f1 0.6436 > 0.6366 at epoch 21			
Found new best macro-f1 0.6499 > 0.6436 at epoch 27			
Found new best macro-f1 0.6525 > 0.6499 at epoch 41			
Found new best macro-f1 0.6553 > 0.6525 at epoch 42			
Found new best macro-f1 0.6644 > 0.6553 at epoch 55			
Found new best macro-f1 0.6661 > 0.6644 at epoch 58			
Found new best macro-f1 0.6716 > 0.6661 at epoch 65			

Max patience 21/20 reached!
Loading model from epoch 65 with macro-f1 0.6716
              precision    recall  f1-score   support

           0      0.919     0.966     0.942      1910
           1      0.543     0.318     0.401       239

    accuracy                          0.894      2149
   macro avg      0.731     0.642     0.672      2149
weighted avg      0.877     0.894     0.882      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005


======================================================================
Running grid search iteration 39/100 'H3_v1_39': {'dual_path': [128], 'layers': [256, 128, 64], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': False, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6039 > 0.0000 at epoch 1			
Found new best macro-f1 0.6042 > 0.6039 at epoch 2			
Found new best macro-f1 0.6268 > 0.6042 at epoch 4			
Found new best macro-f1 0.6534 > 0.6268 at epoch 7			
Found new best macro-f1 0.6899 > 0.6534 at epoch 16			
Found new best macro-f1 0.6981 > 0.6899 at epoch 25			
Found new best macro-f1 0.7302 > 0.6981 at epoch 27			

Max patience 21/20 reached!
Loading model from epoch 27 with macro-f1 0.7302
              precision    recall  f1-score   support

           0      0.936     0.953     0.945      1910
           1      0.562     0.477     0.516       239

    accuracy                          0.900      2149
   macro avg      0.749     0.715     0.730      2149
weighted avg      0.894     0.900     0.897      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005


======================================================================
Running grid search iteration 40/100 'H3_v1_40': {'dual_path': [128, 64], 'layers': [256, 128, 64], 'input_drop': 0.3, 'other_drop': 0.5, 'bn': False, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5223 > 0.4706 at epoch 3			
Found new best macro-f1 0.5322 > 0.5223 at epoch 4			
Found new best macro-f1 0.5607 > 0.5322 at epoch 5			
Found new best macro-f1 0.5859 > 0.5607 at epoch 6			
Found new best macro-f1 0.5908 > 0.5859 at epoch 8			
Found new best macro-f1 0.5938 > 0.5908 at epoch 9			
Found new best macro-f1 0.5967 > 0.5938 at epoch 10			
Found new best macro-f1 0.6111 > 0.5967 at epoch 11			
Found new best macro-f1 0.6116 > 0.6111 at epoch 13			
Found new best macro-f1 0.6144 > 0.6116 at epoch 14			
Found new best macro-f1 0.6164 > 0.6144 at epoch 17			
Found new best macro-f1 0.6202 > 0.6164 at epoch 19			
Found new best macro-f1 0.6223 > 0.6202 at epoch 20			
Found new best macro-f1 0.6273 > 0.6223 at epoch 22			
Found new best macro-f1 0.6417 > 0.6273 at epoch 36			

Max patience 21/20 reached!
Loading model from epoch 36 with macro-f1 0.6417
              precision    recall  f1-score   support

           0      0.912     0.973     0.941      1910
           1      0.536     0.251     0.342       239

    accuracy                          0.893      2149
   macro avg      0.724     0.612     0.642      2149
weighted avg      0.870     0.893     0.875      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005


======================================================================
Running grid search iteration 41/100 'H3_v1_41': {'dual_path': [128, 64], 'layers': [64], 'input_drop': 0, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5529 > 0.4706 at epoch 2			
Found new best macro-f1 0.6357 > 0.5529 at epoch 3			
Found new best macro-f1 0.6378 > 0.6357 at epoch 4			
Found new best macro-f1 0.6594 > 0.6378 at epoch 7			
Found new best macro-f1 0.6886 > 0.6594 at epoch 9			
Found new best macro-f1 0.6941 > 0.6886 at epoch 10			

Max patience 21/20 reached!
Loading model from epoch 10 with macro-f1 0.6941
              precision    recall  f1-score   support

           0      0.929     0.942     0.936      1910
           1      0.481     0.427     0.452       239

    accuracy                          0.885      2149
   macro avg      0.705     0.685     0.694      2149
weighted avg      0.879     0.885     0.882      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005


======================================================================
Running grid search iteration 42/100 'H3_v1_42': {'dual_path': [128], 'layers': [256, 128, 64], 'input_drop': 0.3, 'other_drop': 0.5, 'bn': False, 'bn_inputs': False, 'activ': 'relu', 'eta': 0.0005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5738 > 0.4706 at epoch 17			
Found new best macro-f1 0.6801 > 0.5738 at epoch 18			
Found new best macro-f1 0.6965 > 0.6801 at epoch 19			
Found new best macro-f1 0.6984 > 0.6965 at epoch 20			
Found new best macro-f1 0.7038 > 0.6984 at epoch 21			

Max patience 21/20 reached!
Loading model from epoch 21 with macro-f1 0.7038
              precision    recall  f1-score   support

           0      0.930     0.949     0.939      1910
           1      0.512     0.431     0.468       239

    accuracy                          0.891      2149
   macro avg      0.721     0.690     0.704      2149
weighted avg      0.884     0.891     0.887      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005


======================================================================
Running grid search iteration 43/100 'H3_v1_43': {'dual_path': [128, 64], 'layers': [64], 'input_drop': 0, 'other_drop': 0.5, 'bn': False, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6002 > 0.0000 at epoch 1			
Found new best macro-f1 0.6199 > 0.6002 at epoch 3			
Found new best macro-f1 0.6214 > 0.6199 at epoch 4			
Found new best macro-f1 0.6345 > 0.6214 at epoch 6			
Found new best macro-f1 0.6398 > 0.6345 at epoch 10			
Found new best macro-f1 0.6407 > 0.6398 at epoch 11			
Found new best macro-f1 0.6562 > 0.6407 at epoch 13			

Max patience 21/20 reached!
Loading model from epoch 13 with macro-f1 0.6562
              precision    recall  f1-score   support

           0      0.922     0.930     0.926      1910
           1      0.401     0.372     0.386       239

    accuracy                          0.868      2149
   macro avg      0.662     0.651     0.656      2149
weighted avg      0.864     0.868     0.866      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005


======================================================================
Running grid search iteration 44/100 'H3_v1_44': {'dual_path': [128], 'layers': [128, 64], 'input_drop': 0.3, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6111 > 0.0000 at epoch 1			
Found new best macro-f1 0.6416 > 0.6111 at epoch 2			
Found new best macro-f1 0.6696 > 0.6416 at epoch 3			
Found new best macro-f1 0.6847 > 0.6696 at epoch 4			

Max patience 21/20 reached!
Loading model from epoch 4 with macro-f1 0.6847
              precision    recall  f1-score   support

           0      0.929     0.933     0.931      1910
           1      0.446     0.431     0.438       239

    accuracy                          0.877      2149
   macro avg      0.687     0.682     0.685      2149
weighted avg      0.875     0.877     0.876      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005


======================================================================
Running grid search iteration 45/100 'H3_v1_45': {'dual_path': [128], 'layers': [128, 32], 'input_drop': 0.3, 'other_drop': 0, 'bn': True, 'bn_inputs': False, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6616 > 0.0000 at epoch 1			
Found new best macro-f1 0.6686 > 0.6616 at epoch 9			
Found new best macro-f1 0.6857 > 0.6686 at epoch 11			
Found new best macro-f1 0.6954 > 0.6857 at epoch 13			
Found new best macro-f1 0.7009 > 0.6954 at epoch 33			

Max patience 21/20 reached!
Loading model from epoch 33 with macro-f1 0.7009
              precision    recall  f1-score   support

           0      0.926     0.963     0.944      1910
           1      0.564     0.385     0.458       239

    accuracy                          0.899      2149
   macro avg      0.745     0.674     0.701      2149
weighted avg      0.886     0.899     0.890      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005


======================================================================
Running grid search iteration 46/100 'H3_v1_46': {'dual_path': [128, 64], 'layers': [64], 'input_drop': 0, 'other_drop': 0, 'bn': False, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5152 > 0.0000 at epoch 1			
Found new best macro-f1 0.5889 > 0.5152 at epoch 2			
Found new best macro-f1 0.6022 > 0.5889 at epoch 3			
Found new best macro-f1 0.6222 > 0.6022 at epoch 4			
Found new best macro-f1 0.6286 > 0.6222 at epoch 5			
Found new best macro-f1 0.6756 > 0.6286 at epoch 7			

Max patience 21/20 reached!
Loading model from epoch 7 with macro-f1 0.6756
              precision    recall  f1-score   support

           0      0.923     0.948     0.935      1910
           1      0.471     0.372     0.416       239

    accuracy                          0.884      2149
   macro avg      0.697     0.660     0.676      2149
weighted avg      0.873     0.884     0.878      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005


======================================================================
Running grid search iteration 47/100 'H3_v1_47': {'dual_path': [128, 64], 'layers': [128, 64], 'input_drop': 0.3, 'other_drop': 0, 'bn': False, 'bn_inputs': False, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5859 > 0.4706 at epoch 4			
Found new best macro-f1 0.6670 > 0.5859 at epoch 5			
Found new best macro-f1 0.6841 > 0.6670 at epoch 7			

Max patience 21/20 reached!
Loading model from epoch 7 with macro-f1 0.6841
              precision    recall  f1-score   support

           0      0.928     0.936     0.932      1910
           1      0.451     0.423     0.436       239

    accuracy                          0.879      2149
   macro avg      0.690     0.679     0.684      2149
weighted avg      0.875     0.879     0.877      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005


======================================================================
Running grid search iteration 48/100 'H3_v1_48': {'dual_path': [128, 64], 'layers': [256, 128, 64], 'input_drop': 0.3, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5770 > 0.4706 at epoch 7			
Found new best macro-f1 0.6143 > 0.5770 at epoch 8			
Found new best macro-f1 0.6632 > 0.6143 at epoch 9			
Found new best macro-f1 0.6663 > 0.6632 at epoch 12			
Found new best macro-f1 0.6804 > 0.6663 at epoch 21			
Found new best macro-f1 0.6867 > 0.6804 at epoch 26			
Found new best macro-f1 0.6913 > 0.6867 at epoch 28			
Found new best macro-f1 0.6975 > 0.6913 at epoch 29			
Found new best macro-f1 0.7010 > 0.6975 at epoch 33			
Found new best macro-f1 0.7053 > 0.7010 at epoch 40			

Max patience 21/20 reached!
Loading model from epoch 40 with macro-f1 0.7053
              precision    recall  f1-score   support

           0      0.930     0.951     0.940      1910
           1      0.523     0.427     0.470       239

    accuracy                          0.893      2149
   macro avg      0.726     0.689     0.705      2149
weighted avg      0.885     0.893     0.888      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005


======================================================================
Running grid search iteration 49/100 'H3_v1_49': {'dual_path': [128], 'layers': [64], 'input_drop': 0, 'other_drop': 0.3, 'bn': True, 'bn_inputs': False, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5844 > 0.0000 at epoch 1			
Found new best macro-f1 0.6351 > 0.5844 at epoch 2			
Found new best macro-f1 0.6825 > 0.6351 at epoch 3			

Max patience 21/20 reached!
Loading model from epoch 3 with macro-f1 0.6825
              precision    recall  f1-score   support

           0      0.935     0.908     0.921      1910
           1      0.403     0.494     0.444       239

    accuracy                          0.862      2149
   macro avg      0.669     0.701     0.683      2149
weighted avg      0.876     0.862     0.868      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005


======================================================================
Running grid search iteration 50/100 'H3_v1_50': {'dual_path': [128, 64], 'layers': [128, 32], 'input_drop': 0.3, 'other_drop': 0, 'bn': True, 'bn_inputs': True, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.3958 > 0.0000 at epoch 1			
Found new best macro-f1 0.5605 > 0.3958 at epoch 2			
Found new best macro-f1 0.5978 > 0.5605 at epoch 3			
Found new best macro-f1 0.6090 > 0.5978 at epoch 4			
Found new best macro-f1 0.6220 > 0.6090 at epoch 5			
Found new best macro-f1 0.6403 > 0.6220 at epoch 6			
Found new best macro-f1 0.6456 > 0.6403 at epoch 7			
Found new best macro-f1 0.6512 > 0.6456 at epoch 8			
Found new best macro-f1 0.6516 > 0.6512 at epoch 11			
Found new best macro-f1 0.6575 > 0.6516 at epoch 12			
Found new best macro-f1 0.6666 > 0.6575 at epoch 13			
Found new best macro-f1 0.6686 > 0.6666 at epoch 14			
Found new best macro-f1 0.6818 > 0.6686 at epoch 15			
Found new best macro-f1 0.6935 > 0.6818 at epoch 16			
Found new best macro-f1 0.6996 > 0.6935 at epoch 19			
Found new best macro-f1 0.7013 > 0.6996 at epoch 25			
Found new best macro-f1 0.7097 > 0.7013 at epoch 28			

Max patience 21/20 reached!
Loading model from epoch 28 with macro-f1 0.7097
              precision    recall  f1-score   support

           0      0.938     0.927     0.932      1910
           1      0.466     0.510     0.487       239

    accuracy                          0.880      2149
   macro avg      0.702     0.719     0.710      2149
weighted avg      0.885     0.880     0.883      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005


======================================================================
Running grid search iteration 51/100 'H3_v1_51': {'dual_path': None, 'layers': [256, 128, 64], 'input_drop': 0, 'other_drop': 0.3, 'bn': False, 'bn_inputs': False, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.4998 > 0.4706 at epoch 2			
Found new best macro-f1 0.6398 > 0.4998 at epoch 3			
Found new best macro-f1 0.6747 > 0.6398 at epoch 4			
Found new best macro-f1 0.6904 > 0.6747 at epoch 5			
Found new best macro-f1 0.6915 > 0.6904 at epoch 16			
Found new best macro-f1 0.7013 > 0.6915 at epoch 28			
Found new best macro-f1 0.7112 > 0.7013 at epoch 33			

Max patience 21/20 reached!
Loading model from epoch 33 with macro-f1 0.7112
              precision    recall  f1-score   support

           0      0.932     0.949     0.940      1910
           1      0.522     0.448     0.482       239

    accuracy                          0.893      2149
   macro avg      0.727     0.698     0.711      2149
weighted avg      0.886     0.893     0.889      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005


======================================================================
Running grid search iteration 52/100 'H3_v1_52': {'dual_path': [128], 'layers': [256, 128, 64], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': True, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5651 > 0.0000 at epoch 1			
Found new best macro-f1 0.6628 > 0.5651 at epoch 2			
Found new best macro-f1 0.6657 > 0.6628 at epoch 8			
Found new best macro-f1 0.6796 > 0.6657 at epoch 10			
Found new best macro-f1 0.7049 > 0.6796 at epoch 13			
Found new best macro-f1 0.7077 > 0.7049 at epoch 26			
Found new best macro-f1 0.7275 > 0.7077 at epoch 29			
Found new best macro-f1 0.7324 > 0.7275 at epoch 30			
Found new best macro-f1 0.7369 > 0.7324 at epoch 39			

Max patience 21/20 reached!
Loading model from epoch 39 with macro-f1 0.7369
              precision    recall  f1-score   support

           0      0.942     0.939     0.941      1910
           1      0.527     0.540     0.533       239

    accuracy                          0.895      2149
   macro avg      0.734     0.740     0.737      2149
weighted avg      0.896     0.895     0.895      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 53/100 'H3_v1_53': {'dual_path': [128], 'layers': [64], 'input_drop': 0.3, 'other_drop': 0, 'bn': True, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6094 > 0.0000 at epoch 1			
Found new best macro-f1 0.6287 > 0.6094 at epoch 4			
Found new best macro-f1 0.6629 > 0.6287 at epoch 5			
Found new best macro-f1 0.6706 > 0.6629 at epoch 8			
Found new best macro-f1 0.6722 > 0.6706 at epoch 11			
Found new best macro-f1 0.6775 > 0.6722 at epoch 21			
Found new best macro-f1 0.6802 > 0.6775 at epoch 31			

Max patience 21/20 reached!
Loading model from epoch 31 with macro-f1 0.6802
              precision    recall  f1-score   support

           0      0.920     0.968     0.944      1910
           1      0.564     0.331     0.417       239

    accuracy                          0.897      2149
   macro avg      0.742     0.649     0.680      2149
weighted avg      0.881     0.897     0.885      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 54/100 'H3_v1_54': {'dual_path': [128], 'layers': [64], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': False, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4831 > 0.0000 at epoch 1			
Found new best macro-f1 0.4914 > 0.4831 at epoch 2			
Found new best macro-f1 0.5107 > 0.4914 at epoch 3			
Found new best macro-f1 0.5660 > 0.5107 at epoch 4			
Found new best macro-f1 0.5797 > 0.5660 at epoch 5			
Found new best macro-f1 0.6100 > 0.5797 at epoch 6			
Found new best macro-f1 0.6122 > 0.6100 at epoch 8			
Found new best macro-f1 0.6138 > 0.6122 at epoch 10			
Found new best macro-f1 0.6160 > 0.6138 at epoch 12			
Found new best macro-f1 0.6206 > 0.6160 at epoch 15			
Found new best macro-f1 0.6263 > 0.6206 at epoch 22			
Found new best macro-f1 0.6285 > 0.6263 at epoch 36			
Found new best macro-f1 0.6303 > 0.6285 at epoch 55			
Found new best macro-f1 0.6319 > 0.6303 at epoch 56			
Found new best macro-f1 0.6321 > 0.6319 at epoch 68			

Max patience 21/20 reached!
Loading model from epoch 68 with macro-f1 0.6321
              precision    recall  f1-score   support

           0      0.910     0.975     0.942      1910
           1      0.539     0.230     0.323       239

    accuracy                          0.893      2149
   macro avg      0.725     0.603     0.632      2149
weighted avg      0.869     0.893     0.873      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 55/100 'H3_v1_55': {'dual_path': None, 'layers': [128, 32], 'input_drop': 0, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6194 > 0.0000 at epoch 1			
Found new best macro-f1 0.6322 > 0.6194 at epoch 2			
Found new best macro-f1 0.6332 > 0.6322 at epoch 6			
Found new best macro-f1 0.6372 > 0.6332 at epoch 7			
Found new best macro-f1 0.6382 > 0.6372 at epoch 8			
Found new best macro-f1 0.6386 > 0.6382 at epoch 12			
Found new best macro-f1 0.6423 > 0.6386 at epoch 13			
Found new best macro-f1 0.6458 > 0.6423 at epoch 14			
Found new best macro-f1 0.6490 > 0.6458 at epoch 16			
Found new best macro-f1 0.6521 > 0.6490 at epoch 17			
Found new best macro-f1 0.6576 > 0.6521 at epoch 22			
Found new best macro-f1 0.6670 > 0.6576 at epoch 33			

Max patience 21/20 reached!
Loading model from epoch 33 with macro-f1 0.6670
              precision    recall  f1-score   support

           0      0.931     0.904     0.917      1910
           1      0.378     0.464     0.417       239

    accuracy                          0.855      2149
   macro avg      0.654     0.684     0.667      2149
weighted avg      0.869     0.855     0.862      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 56/100 'H3_v1_56': {'dual_path': [128, 64], 'layers': [256, 128, 64], 'input_drop': 0.3, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5827 > 0.0000 at epoch 1			
Found new best macro-f1 0.5849 > 0.5827 at epoch 2			
Found new best macro-f1 0.5858 > 0.5849 at epoch 4			
Found new best macro-f1 0.5937 > 0.5858 at epoch 5			
Found new best macro-f1 0.6053 > 0.5937 at epoch 6			
Found new best macro-f1 0.6096 > 0.6053 at epoch 7			
Found new best macro-f1 0.6104 > 0.6096 at epoch 8			
Found new best macro-f1 0.6249 > 0.6104 at epoch 9			
Found new best macro-f1 0.6262 > 0.6249 at epoch 10			
Found new best macro-f1 0.6432 > 0.6262 at epoch 11			
Found new best macro-f1 0.6531 > 0.6432 at epoch 12			
Found new best macro-f1 0.6553 > 0.6531 at epoch 13			
Found new best macro-f1 0.6557 > 0.6553 at epoch 15			
Found new best macro-f1 0.6590 > 0.6557 at epoch 16			
Found new best macro-f1 0.6618 > 0.6590 at epoch 17			
Found new best macro-f1 0.6669 > 0.6618 at epoch 18			
Found new best macro-f1 0.6787 > 0.6669 at epoch 19			
Found new best macro-f1 0.6864 > 0.6787 at epoch 20			
Found new best macro-f1 0.6891 > 0.6864 at epoch 21			
Found new best macro-f1 0.6970 > 0.6891 at epoch 22			
Found new best macro-f1 0.6973 > 0.6970 at epoch 23			
Found new best macro-f1 0.6979 > 0.6973 at epoch 27			
Found new best macro-f1 0.7017 > 0.6979 at epoch 28			

Max patience 21/20 reached!
Loading model from epoch 28 with macro-f1 0.7017
              precision    recall  f1-score   support

           0      0.932     0.940     0.936      1910
           1      0.484     0.452     0.468       239

    accuracy                          0.886      2149
   macro avg      0.708     0.696     0.702      2149
weighted avg      0.882     0.886     0.884      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 57/100 'H3_v1_57': {'dual_path': [128], 'layers': [128, 32], 'input_drop': 0, 'other_drop': 0, 'bn': False, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.3 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4747 > 0.0000 at epoch 1			
Found new best macro-f1 0.5060 > 0.4747 at epoch 2			
Found new best macro-f1 0.5543 > 0.5060 at epoch 3			
Found new best macro-f1 0.5994 > 0.5543 at epoch 4			
Found new best macro-f1 0.6272 > 0.5994 at epoch 5			
Found new best macro-f1 0.6398 > 0.6272 at epoch 6			
Found new best macro-f1 0.6445 > 0.6398 at epoch 7			
Found new best macro-f1 0.6513 > 0.6445 at epoch 8			
Found new best macro-f1 0.6528 > 0.6513 at epoch 11			

Max patience 21/20 reached!
Loading model from epoch 11 with macro-f1 0.6528
              precision    recall  f1-score   support

           0      0.918     0.951     0.934      1910
           1      0.447     0.318     0.372       239

    accuracy                          0.880      2149
   macro avg      0.682     0.634     0.653      2149
weighted avg      0.865     0.880     0.871      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 58/100 'H3_v1_58': {'dual_path': [128, 64], 'layers': [128, 32], 'input_drop': 0.3, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4808 > 0.0000 at epoch 1			
Found new best macro-f1 0.5858 > 0.4808 at epoch 2			
Found new best macro-f1 0.6191 > 0.5858 at epoch 3			
Found new best macro-f1 0.6527 > 0.6191 at epoch 4			
Found new best macro-f1 0.6541 > 0.6527 at epoch 6			
Found new best macro-f1 0.6584 > 0.6541 at epoch 7			
Found new best macro-f1 0.6712 > 0.6584 at epoch 8			
Found new best macro-f1 0.6776 > 0.6712 at epoch 15			
Found new best macro-f1 0.6778 > 0.6776 at epoch 16			
Found new best macro-f1 0.6882 > 0.6778 at epoch 17			
Found new best macro-f1 0.6902 > 0.6882 at epoch 22			
Found new best macro-f1 0.6942 > 0.6902 at epoch 24			
Found new best macro-f1 0.6944 > 0.6942 at epoch 25			

Max patience 21/20 reached!
Loading model from epoch 25 with macro-f1 0.6944
              precision    recall  f1-score   support

           0      0.933     0.929     0.931      1910
           1      0.451     0.464     0.458       239

    accuracy                          0.878      2149
   macro avg      0.692     0.697     0.694      2149
weighted avg      0.879     0.878     0.878      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 59/100 'H3_v1_59': {'dual_path': None, 'layers': [128, 32], 'input_drop': 0.3, 'other_drop': 0.5, 'bn': False, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6208 > 0.0000 at epoch 1			
Found new best macro-f1 0.6482 > 0.6208 at epoch 2			

Max patience 21/20 reached!
Loading model from epoch 2 with macro-f1 0.6482
              precision    recall  f1-score   support

           0      0.914     0.968     0.940      1910
           1      0.516     0.272     0.356       239

    accuracy                          0.891      2149
   macro avg      0.715     0.620     0.648      2149
weighted avg      0.870     0.891     0.875      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 60/100 'H3_v1_60': {'dual_path': [128, 64], 'layers': [128, 64], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': True, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.1300 > 0.0000 at epoch 1			
Found new best macro-f1 0.4377 > 0.1300 at epoch 2			
Found new best macro-f1 0.5206 > 0.4377 at epoch 3			
Found new best macro-f1 0.5596 > 0.5206 at epoch 4			
Found new best macro-f1 0.5787 > 0.5596 at epoch 5			
Found new best macro-f1 0.5858 > 0.5787 at epoch 6			
Found new best macro-f1 0.5999 > 0.5858 at epoch 7			
Found new best macro-f1 0.6116 > 0.5999 at epoch 9			
Found new best macro-f1 0.6195 > 0.6116 at epoch 10			
Found new best macro-f1 0.6243 > 0.6195 at epoch 11			
Found new best macro-f1 0.6438 > 0.6243 at epoch 12			
Found new best macro-f1 0.6457 > 0.6438 at epoch 13			
Found new best macro-f1 0.6545 > 0.6457 at epoch 14			
Found new best macro-f1 0.6657 > 0.6545 at epoch 15			
Found new best macro-f1 0.6745 > 0.6657 at epoch 17			
Found new best macro-f1 0.6758 > 0.6745 at epoch 18			
Found new best macro-f1 0.6799 > 0.6758 at epoch 21			

Max patience 21/20 reached!
Loading model from epoch 21 with macro-f1 0.6799
              precision    recall  f1-score   support

           0      0.927     0.937     0.932      1910
           1      0.447     0.410     0.428       239

    accuracy                          0.878      2149
   macro avg      0.687     0.673     0.680      2149
weighted avg      0.874     0.878     0.876      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 61/100 'H3_v1_61': {'dual_path': None, 'layers': [128, 32], 'input_drop': 0, 'other_drop': 0.3, 'bn': True, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6451 > 0.0000 at epoch 1			
Found new best macro-f1 0.6856 > 0.6451 at epoch 2			

Max patience 21/20 reached!
Loading model from epoch 2 with macro-f1 0.6856
              precision    recall  f1-score   support

           0      0.938     0.901     0.919      1910
           1      0.398     0.523     0.452       239

    accuracy                          0.859      2149
   macro avg      0.668     0.712     0.686      2149
weighted avg      0.878     0.859     0.867      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 62/100 'H3_v1_62': {'dual_path': [128], 'layers': [256, 128, 64], 'input_drop': 0, 'other_drop': 0, 'bn': True, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6767 > 0.0000 at epoch 1			

Max patience 21/20 reached!
Loading model from epoch 1 with macro-f1 0.6767
              precision    recall  f1-score   support

           0      0.943     0.872     0.906      1910
           1      0.363     0.582     0.447       239

    accuracy                          0.840      2149
   macro avg      0.653     0.727     0.677      2149
weighted avg      0.879     0.840     0.855      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 63/100 'H3_v1_63': {'dual_path': None, 'layers': [128, 64], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': False, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4951 > 0.0000 at epoch 1			
Found new best macro-f1 0.5060 > 0.4951 at epoch 2			
Found new best macro-f1 0.5361 > 0.5060 at epoch 3			
Found new best macro-f1 0.5762 > 0.5361 at epoch 4			
Found new best macro-f1 0.6089 > 0.5762 at epoch 5			
Found new best macro-f1 0.6111 > 0.6089 at epoch 6			
Found new best macro-f1 0.6240 > 0.6111 at epoch 8			

Max patience 21/20 reached!
Loading model from epoch 8 with macro-f1 0.6240
              precision    recall  f1-score   support

           0      0.909     0.977     0.942      1910
           1      0.543     0.213     0.306       239

    accuracy                          0.893      2149
   macro avg      0.726     0.595     0.624      2149
weighted avg      0.868     0.893     0.871      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 64/100 'H3_v1_64': {'dual_path': [128], 'layers': [64], 'input_drop': 0.3, 'other_drop': 0.5, 'bn': True, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6042 > 0.0000 at epoch 1			
Found new best macro-f1 0.6398 > 0.6042 at epoch 2			
Found new best macro-f1 0.6938 > 0.6398 at epoch 3			

Max patience 21/20 reached!
Loading model from epoch 3 with macro-f1 0.6938
              precision    recall  f1-score   support

           0      0.927     0.951     0.939      1910
           1      0.508     0.402     0.449       239

    accuracy                          0.890      2149
   macro avg      0.717     0.676     0.694      2149
weighted avg      0.880     0.890     0.884      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 65/100 'H3_v1_65': {'dual_path': [128, 64], 'layers': [128, 64], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': False, 'bn_inputs': True, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.4986 > 0.4706 at epoch 2			
Found new best macro-f1 0.5660 > 0.4986 at epoch 3			
Found new best macro-f1 0.5895 > 0.5660 at epoch 4			
Found new best macro-f1 0.6089 > 0.5895 at epoch 5			
Found new best macro-f1 0.6169 > 0.6089 at epoch 6			
Found new best macro-f1 0.6180 > 0.6169 at epoch 7			
Found new best macro-f1 0.6231 > 0.6180 at epoch 8			
Found new best macro-f1 0.6295 > 0.6231 at epoch 12			
Found new best macro-f1 0.6344 > 0.6295 at epoch 15			
Found new best macro-f1 0.6354 > 0.6344 at epoch 20			
Found new best macro-f1 0.6373 > 0.6354 at epoch 22			
Found new best macro-f1 0.6434 > 0.6373 at epoch 28			
Found new best macro-f1 0.6435 > 0.6434 at epoch 49			
Found new best macro-f1 0.6458 > 0.6435 at epoch 70			
Found new best macro-f1 0.6521 > 0.6458 at epoch 72			
Found new best macro-f1 0.6546 > 0.6521 at epoch 83			

Max patience 21/20 reached!
Loading model from epoch 83 with macro-f1 0.6546
              precision    recall  f1-score   support

           0      0.915     0.968     0.941      1910
           1      0.523     0.285     0.369       239

    accuracy                          0.892      2149
   macro avg      0.719     0.626     0.655      2149
weighted avg      0.872     0.892     0.877      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 66/100 'H3_v1_66': {'dual_path': [128, 64], 'layers': [128, 32], 'input_drop': 0, 'other_drop': 0, 'bn': True, 'bn_inputs': False, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6246 > 0.0000 at epoch 1			
Found new best macro-f1 0.6781 > 0.6246 at epoch 2			
Found new best macro-f1 0.6817 > 0.6781 at epoch 6			
Found new best macro-f1 0.6824 > 0.6817 at epoch 13			
Found new best macro-f1 0.6831 > 0.6824 at epoch 20			

Max patience 21/20 reached!
Loading model from epoch 20 with macro-f1 0.6831
              precision    recall  f1-score   support

           0      0.932     0.919     0.926      1910
           1      0.419     0.464     0.440       239

    accuracy                          0.869      2149
   macro avg      0.675     0.692     0.683      2149
weighted avg      0.875     0.869     0.872      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 67/100 'H3_v1_67': {'dual_path': None, 'layers': [128, 32], 'input_drop': 0.3, 'other_drop': 0, 'bn': False, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5892 > 0.0000 at epoch 1			
Found new best macro-f1 0.6049 > 0.5892 at epoch 2			
Found new best macro-f1 0.6179 > 0.6049 at epoch 3			
Found new best macro-f1 0.6413 > 0.6179 at epoch 12			
Found new best macro-f1 0.6671 > 0.6413 at epoch 19			

Max patience 21/20 reached!
Loading model from epoch 19 with macro-f1 0.6671
              precision    recall  f1-score   support

           0      0.920     0.958     0.938      1910
           1      0.494     0.331     0.396       239

    accuracy                          0.888      2149
   macro avg      0.707     0.644     0.667      2149
weighted avg      0.872     0.888     0.878      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 68/100 'H3_v1_68': {'dual_path': None, 'layers': [128, 32], 'input_drop': 0.3, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5991 > 0.0000 at epoch 1			
Found new best macro-f1 0.6032 > 0.5991 at epoch 5			
Found new best macro-f1 0.6077 > 0.6032 at epoch 6			
Found new best macro-f1 0.6083 > 0.6077 at epoch 7			
Found new best macro-f1 0.6179 > 0.6083 at epoch 8			
Found new best macro-f1 0.6272 > 0.6179 at epoch 9			
Found new best macro-f1 0.6282 > 0.6272 at epoch 10			
Found new best macro-f1 0.6384 > 0.6282 at epoch 11			
Found new best macro-f1 0.6399 > 0.6384 at epoch 12			
Found new best macro-f1 0.6425 > 0.6399 at epoch 13			
Found new best macro-f1 0.6481 > 0.6425 at epoch 14			
Found new best macro-f1 0.6507 > 0.6481 at epoch 15			
Found new best macro-f1 0.6586 > 0.6507 at epoch 18			
Found new best macro-f1 0.6703 > 0.6586 at epoch 19			
Found new best macro-f1 0.6734 > 0.6703 at epoch 22			
Found new best macro-f1 0.6737 > 0.6734 at epoch 23			
Found new best macro-f1 0.6794 > 0.6737 at epoch 24			
Found new best macro-f1 0.6822 > 0.6794 at epoch 25			
Found new best macro-f1 0.6826 > 0.6822 at epoch 28			
Found new best macro-f1 0.6909 > 0.6826 at epoch 29			

Max patience 21/20 reached!
Loading model from epoch 29 with macro-f1 0.6909
              precision    recall  f1-score   support

           0      0.934     0.920     0.927      1910
           1      0.431     0.481     0.455       239

    accuracy                          0.872      2149
   macro avg      0.682     0.701     0.691      2149
weighted avg      0.878     0.872     0.875      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 69/100 'H3_v1_69': {'dual_path': [128], 'layers': [256, 128, 64], 'input_drop': 0, 'other_drop': 0, 'bn': True, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5392 > 0.0000 at epoch 1			
Found new best macro-f1 0.5736 > 0.5392 at epoch 2			
Found new best macro-f1 0.6058 > 0.5736 at epoch 3			
Found new best macro-f1 0.6252 > 0.6058 at epoch 6			
Found new best macro-f1 0.6496 > 0.6252 at epoch 14			

Max patience 21/20 reached!
Loading model from epoch 14 with macro-f1 0.6496
              precision    recall  f1-score   support

           0      0.940     0.849     0.892      1910
           1      0.318     0.565     0.407       239

    accuracy                          0.817      2149
   macro avg      0.629     0.707     0.650      2149
weighted avg      0.871     0.817     0.838      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 70/100 'H3_v1_70': {'dual_path': [128, 64], 'layers': [256, 128, 64], 'input_drop': 0, 'other_drop': 0, 'bn': False, 'bn_inputs': True, 'activ': 'tanh', 'eta': 0.005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5941 > 0.0000 at epoch 1			
Found new best macro-f1 0.6010 > 0.5941 at epoch 2			
Found new best macro-f1 0.6123 > 0.6010 at epoch 3			
Found new best macro-f1 0.6275 > 0.6123 at epoch 4			
Found new best macro-f1 0.6391 > 0.6275 at epoch 5			
Found new best macro-f1 0.6543 > 0.6391 at epoch 10			
Found new best macro-f1 0.6688 > 0.6543 at epoch 14			

Max patience 21/20 reached!
Loading model from epoch 14 with macro-f1 0.6688
              precision    recall  f1-score   support

           0      0.927     0.924     0.925      1910
           1      0.407     0.418     0.412       239

    accuracy                          0.867      2149
   macro avg      0.667     0.671     0.669      2149
weighted avg      0.869     0.867     0.868      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 71/100 'H3_v1_71': {'dual_path': [128, 64], 'layers': [128, 64], 'input_drop': 0, 'other_drop': 0.5, 'bn': False, 'bn_inputs': False, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.6094 > 0.4706 at epoch 4			
Found new best macro-f1 0.6323 > 0.6094 at epoch 6			
Found new best macro-f1 0.6351 > 0.6323 at epoch 7			
Found new best macro-f1 0.6740 > 0.6351 at epoch 10			
Found new best macro-f1 0.6780 > 0.6740 at epoch 16			
Found new best macro-f1 0.6804 > 0.6780 at epoch 21			

Max patience 21/20 reached!
Loading model from epoch 21 with macro-f1 0.6804
              precision    recall  f1-score   support

           0      0.930     0.923     0.927      1910
           1      0.421     0.448     0.434       239

    accuracy                          0.870      2149
   macro avg      0.676     0.685     0.680      2149
weighted avg      0.874     0.870     0.872      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 72/100 'H3_v1_72': {'dual_path': [128], 'layers': [128, 64], 'input_drop': 0, 'other_drop': 0, 'bn': True, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6703 > 0.0000 at epoch 1			
Found new best macro-f1 0.6732 > 0.6703 at epoch 2			
Found new best macro-f1 0.6841 > 0.6732 at epoch 4			

Max patience 21/20 reached!
Loading model from epoch 4 with macro-f1 0.6841
              precision    recall  f1-score   support

           0      0.925     0.950     0.937      1910
           1      0.489     0.385     0.431       239

    accuracy                          0.887      2149
   macro avg      0.707     0.667     0.684      2149
weighted avg      0.877     0.887     0.881      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 73/100 'H3_v1_73': {'dual_path': None, 'layers': [128, 64], 'input_drop': 0.3, 'other_drop': 0.5, 'bn': False, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.0005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.4748 > 0.4706 at epoch 6			
Found new best macro-f1 0.5102 > 0.4748 at epoch 7			
Found new best macro-f1 0.5396 > 0.5102 at epoch 8			
Found new best macro-f1 0.5843 > 0.5396 at epoch 9			
Found new best macro-f1 0.6112 > 0.5843 at epoch 10			
Found new best macro-f1 0.6198 > 0.6112 at epoch 11			
Found new best macro-f1 0.6423 > 0.6198 at epoch 12			
Found new best macro-f1 0.6563 > 0.6423 at epoch 13			
Found new best macro-f1 0.6632 > 0.6563 at epoch 14			
Found new best macro-f1 0.6642 > 0.6632 at epoch 15			
Found new best macro-f1 0.6692 > 0.6642 at epoch 16			
Found new best macro-f1 0.6735 > 0.6692 at epoch 17			
Found new best macro-f1 0.6760 > 0.6735 at epoch 19			
Found new best macro-f1 0.6781 > 0.6760 at epoch 20			
Found new best macro-f1 0.6829 > 0.6781 at epoch 21			
Found new best macro-f1 0.6844 > 0.6829 at epoch 24			
Found new best macro-f1 0.6853 > 0.6844 at epoch 25			
Found new best macro-f1 0.6906 > 0.6853 at epoch 27			
Found new best macro-f1 0.6954 > 0.6906 at epoch 28			
Found new best macro-f1 0.6972 > 0.6954 at epoch 29			

Max patience 21/20 reached!
Loading model from epoch 29 with macro-f1 0.6972
              precision    recall  f1-score   support

           0      0.927     0.955     0.941      1910
           1      0.528     0.397     0.453       239

    accuracy                          0.893      2149
   macro avg      0.727     0.676     0.697      2149
weighted avg      0.882     0.893     0.887      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 74/100 'H3_v1_74': {'dual_path': None, 'layers': [128, 32], 'input_drop': 0, 'other_drop': 0.5, 'bn': False, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.0005}
  Time left for grid search completion: 0.2 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.4748 > 0.4706 at epoch 6			
Found new best macro-f1 0.5149 > 0.4748 at epoch 7			
Found new best macro-f1 0.5389 > 0.5149 at epoch 8			
Found new best macro-f1 0.5731 > 0.5389 at epoch 9			
Found new best macro-f1 0.6033 > 0.5731 at epoch 10			
Found new best macro-f1 0.6231 > 0.6033 at epoch 11			
Found new best macro-f1 0.6361 > 0.6231 at epoch 12			
Found new best macro-f1 0.6465 > 0.6361 at epoch 13			
Found new best macro-f1 0.6586 > 0.6465 at epoch 14			
Found new best macro-f1 0.6742 > 0.6586 at epoch 15			
Found new best macro-f1 0.6768 > 0.6742 at epoch 26			

Max patience 21/20 reached!
Loading model from epoch 26 with macro-f1 0.6768
              precision    recall  f1-score   support

           0      0.921     0.959     0.940      1910
           1      0.512     0.347     0.414       239

    accuracy                          0.891      2149
   macro avg      0.717     0.653     0.677      2149
weighted avg      0.876     0.891     0.881      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 75/100 'H3_v1_75': {'dual_path': [128], 'layers': [128, 32], 'input_drop': 0.3, 'other_drop': 0, 'bn': False, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.6723 > 0.4706 at epoch 3			
Found new best macro-f1 0.6747 > 0.6723 at epoch 5			

Max patience 21/20 reached!
Loading model from epoch 5 with macro-f1 0.6747
              precision    recall  f1-score   support

           0      0.920     0.965     0.942      1910
           1      0.542     0.326     0.407       239

    accuracy                          0.894      2149
   macro avg      0.731     0.646     0.675      2149
weighted avg      0.878     0.894     0.883      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 76/100 'H3_v1_76': {'dual_path': [128, 64], 'layers': [64], 'input_drop': 0.3, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6287 > 0.0000 at epoch 1			
Found new best macro-f1 0.6852 > 0.6287 at epoch 2			

Max patience 21/20 reached!
Loading model from epoch 2 with macro-f1 0.6852
              precision    recall  f1-score   support

           0      0.937     0.902     0.919      1910
           1      0.399     0.519     0.451       239

    accuracy                          0.859      2149
   macro avg      0.668     0.710     0.685      2149
weighted avg      0.878     0.859     0.867      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 77/100 'H3_v1_77': {'dual_path': None, 'layers': [256, 128, 64], 'input_drop': 0, 'other_drop': 0.5, 'bn': False, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6202 > 0.0000 at epoch 1			
Found new best macro-f1 0.6324 > 0.6202 at epoch 3			
Found new best macro-f1 0.6397 > 0.6324 at epoch 5			

Max patience 21/20 reached!
Loading model from epoch 5 with macro-f1 0.6397
              precision    recall  f1-score   support

           0      0.919     0.927     0.923      1910
           1      0.371     0.343     0.357       239

    accuracy                          0.862      2149
   macro avg      0.645     0.635     0.640      2149
weighted avg      0.858     0.862     0.860      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 78/100 'H3_v1_78': {'dual_path': [128], 'layers': [128, 64], 'input_drop': 0, 'other_drop': 0.3, 'bn': False, 'bn_inputs': False, 'activ': 'relu', 'eta': 0.0005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.4789 > 0.4706 at epoch 8			
Found new best macro-f1 0.5296 > 0.4789 at epoch 9			
Found new best macro-f1 0.5721 > 0.5296 at epoch 10			
Found new best macro-f1 0.6206 > 0.5721 at epoch 11			
Found new best macro-f1 0.6505 > 0.6206 at epoch 12			
Found new best macro-f1 0.6631 > 0.6505 at epoch 13			
Found new best macro-f1 0.6655 > 0.6631 at epoch 14			
Found new best macro-f1 0.6744 > 0.6655 at epoch 15			
Found new best macro-f1 0.6840 > 0.6744 at epoch 16			

Max patience 21/20 reached!
Loading model from epoch 16 with macro-f1 0.6840
              precision    recall  f1-score   support

           0      0.921     0.968     0.944      1910
           1      0.566     0.339     0.424       239

    accuracy                          0.898      2149
   macro avg      0.744     0.653     0.684      2149
weighted avg      0.882     0.898     0.886      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 79/100 'H3_v1_79': {'dual_path': [128], 'layers': [256, 128, 64], 'input_drop': 0, 'other_drop': 0.3, 'bn': False, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.0005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5858 > 0.4706 at epoch 7			
Found new best macro-f1 0.6603 > 0.5858 at epoch 8			
Found new best macro-f1 0.6896 > 0.6603 at epoch 9			
Found new best macro-f1 0.7117 > 0.6896 at epoch 10			
Found new best macro-f1 0.7120 > 0.7117 at epoch 11			

Max patience 21/20 reached!
Loading model from epoch 11 with macro-f1 0.7120
              precision    recall  f1-score   support

           0      0.931     0.955     0.943      1910
           1      0.545     0.431     0.481       239

    accuracy                          0.897      2149
   macro avg      0.738     0.693     0.712      2149
weighted avg      0.888     0.897     0.891      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 80/100 'H3_v1_80': {'dual_path': None, 'layers': [128, 64], 'input_drop': 0, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5737 > 0.0000 at epoch 1			
Found new best macro-f1 0.5978 > 0.5737 at epoch 2			
Found new best macro-f1 0.6021 > 0.5978 at epoch 7			
Found new best macro-f1 0.6025 > 0.6021 at epoch 9			
Found new best macro-f1 0.6115 > 0.6025 at epoch 10			
Found new best macro-f1 0.6231 > 0.6115 at epoch 11			
Found new best macro-f1 0.6274 > 0.6231 at epoch 14			
Found new best macro-f1 0.6409 > 0.6274 at epoch 15			
Found new best macro-f1 0.6521 > 0.6409 at epoch 17			
Found new best macro-f1 0.6523 > 0.6521 at epoch 20			
Found new best macro-f1 0.6591 > 0.6523 at epoch 21			
Found new best macro-f1 0.6729 > 0.6591 at epoch 22			
Found new best macro-f1 0.6733 > 0.6729 at epoch 30			
Found new best macro-f1 0.6763 > 0.6733 at epoch 33			
Found new best macro-f1 0.6805 > 0.6763 at epoch 34			

Max patience 21/20 reached!
Loading model from epoch 34 with macro-f1 0.6805
              precision    recall  f1-score   support

           0      0.928     0.932     0.930      1910
           1      0.439     0.423     0.431       239

    accuracy                          0.876      2149
   macro avg      0.684     0.678     0.680      2149
weighted avg      0.874     0.876     0.875      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 81/100 'H3_v1_81': {'dual_path': [128, 64], 'layers': [128, 64], 'input_drop': 0, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6093 > 0.0000 at epoch 1			
Found new best macro-f1 0.6104 > 0.6093 at epoch 2			
Found new best macro-f1 0.6119 > 0.6104 at epoch 3			
Found new best macro-f1 0.6171 > 0.6119 at epoch 4			
Found new best macro-f1 0.6347 > 0.6171 at epoch 5			
Found new best macro-f1 0.6348 > 0.6347 at epoch 6			
Found new best macro-f1 0.6421 > 0.6348 at epoch 7			
Found new best macro-f1 0.6430 > 0.6421 at epoch 9			
Found new best macro-f1 0.6439 > 0.6430 at epoch 10			
Found new best macro-f1 0.6489 > 0.6439 at epoch 11			
Found new best macro-f1 0.6607 > 0.6489 at epoch 12			
Found new best macro-f1 0.6702 > 0.6607 at epoch 16			
Found new best macro-f1 0.6730 > 0.6702 at epoch 18			
Found new best macro-f1 0.6772 > 0.6730 at epoch 19			
Found new best macro-f1 0.6876 > 0.6772 at epoch 20			
Found new best macro-f1 0.6917 > 0.6876 at epoch 25			

Max patience 21/20 reached!
Loading model from epoch 25 with macro-f1 0.6917
              precision    recall  f1-score   support

           0      0.933     0.924     0.929      1910
           1      0.438     0.473     0.455       239

    accuracy                          0.874      2149
   macro avg      0.686     0.698     0.692      2149
weighted avg      0.878     0.874     0.876      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85     H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 82/100 'H3_v1_82': {'dual_path': [128, 64], 'layers': [128, 64], 'input_drop': 0, 'other_drop': 0, 'bn': True, 'bn_inputs': False, 'activ': 'relu', 'eta': 0.0005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.1001 > 0.0000 at epoch 1			
Found new best macro-f1 0.1998 > 0.1001 at epoch 2			
Found new best macro-f1 0.6175 > 0.1998 at epoch 3			
Found new best macro-f1 0.6250 > 0.6175 at epoch 6			
Found new best macro-f1 0.6355 > 0.6250 at epoch 7			
Found new best macro-f1 0.6427 > 0.6355 at epoch 23			
Found new best macro-f1 0.6481 > 0.6427 at epoch 29			
Found new best macro-f1 0.6509 > 0.6481 at epoch 38			
Found new best macro-f1 0.6516 > 0.6509 at epoch 45			
Found new best macro-f1 0.6644 > 0.6516 at epoch 48			
Found new best macro-f1 0.6696 > 0.6644 at epoch 52			
Found new best macro-f1 0.6707 > 0.6696 at epoch 71			

Max patience 21/20 reached!
Loading model from epoch 71 with macro-f1 0.6707
              precision    recall  f1-score   support

           0      0.929     0.917     0.923      1910
           1      0.399     0.439     0.418       239

    accuracy                          0.864      2149
   macro avg      0.664     0.678     0.671      2149
weighted avg      0.870     0.864     0.867      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86     H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85     H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 83/100 'H3_v1_83': {'dual_path': [128], 'layers': [256, 128, 64], 'input_drop': 0.3, 'other_drop': 0.5, 'bn': True, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6363 > 0.0000 at epoch 1			
Found new best macro-f1 0.6368 > 0.6363 at epoch 2			
Found new best macro-f1 0.6761 > 0.6368 at epoch 3			
Found new best macro-f1 0.6906 > 0.6761 at epoch 11			
Found new best macro-f1 0.6919 > 0.6906 at epoch 29			
Found new best macro-f1 0.6966 > 0.6919 at epoch 35			
Found new best macro-f1 0.7023 > 0.6966 at epoch 43			
Found new best macro-f1 0.7054 > 0.7023 at epoch 46			

Max patience 21/20 reached!
Loading model from epoch 46 with macro-f1 0.7054
              precision    recall  f1-score   support

           0      0.928     0.960     0.944      1910
           1      0.558     0.402     0.467       239

    accuracy                          0.898      2149
   macro avg      0.743     0.681     0.705      2149
weighted avg      0.887     0.898     0.891      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86     H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85     H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87     H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 84/100 'H3_v1_84': {'dual_path': [128, 64], 'layers': [128, 64], 'input_drop': 0, 'other_drop': 0.3, 'bn': False, 'bn_inputs': False, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6570 > 0.0000 at epoch 1			
Found new best macro-f1 0.6575 > 0.6570 at epoch 9			

Max patience 21/20 reached!
Loading model from epoch 9 with macro-f1 0.6575
              precision    recall  f1-score   support

           0      0.920     0.944     0.932      1910
           1      0.434     0.343     0.383       239

    accuracy                          0.877      2149
   macro avg      0.677     0.644     0.657      2149
weighted avg      0.866     0.877     0.871      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
88     H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86     H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85     H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87     H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 85/100 'H3_v1_85': {'dual_path': [128, 64], 'layers': [128, 64], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': False, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5116 > 0.4706 at epoch 2			
Found new best macro-f1 0.5812 > 0.5116 at epoch 3			
Found new best macro-f1 0.5838 > 0.5812 at epoch 5			
Found new best macro-f1 0.5889 > 0.5838 at epoch 6			
Found new best macro-f1 0.5935 > 0.5889 at epoch 7			
Found new best macro-f1 0.6104 > 0.5935 at epoch 9			
Found new best macro-f1 0.6131 > 0.6104 at epoch 10			
Found new best macro-f1 0.6210 > 0.6131 at epoch 13			
Found new best macro-f1 0.6319 > 0.6210 at epoch 19			
Found new best macro-f1 0.6327 > 0.6319 at epoch 26			
Found new best macro-f1 0.6398 > 0.6327 at epoch 27			

Max patience 21/20 reached!
Loading model from epoch 27 with macro-f1 0.6398
              precision    recall  f1-score   support

           0      0.911     0.975     0.942      1910
           1      0.552     0.243     0.337       239

    accuracy                          0.894      2149
   macro avg      0.732     0.609     0.640      2149
weighted avg      0.872     0.894     0.875      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89     H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
88     H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86     H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85     H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87     H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 86/100 'H3_v1_86': {'dual_path': [128], 'layers': [64], 'input_drop': 0, 'other_drop': 0.5, 'bn': True, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6725 > 0.0000 at epoch 1			
Found new best macro-f1 0.6803 > 0.6725 at epoch 2			

Max patience 21/20 reached!
Loading model from epoch 2 with macro-f1 0.6803
              precision    recall  f1-score   support

           0      0.941     0.886     0.912      1910
           1      0.377     0.552     0.448       239

    accuracy                          0.849      2149
   macro avg      0.659     0.719     0.680      2149
weighted avg      0.878     0.849     0.861      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89     H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
88     H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86     H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
90     H3_v1_86  0.680296  concat      [128]            [64]          0        0.5   True      True  selu   0.005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85     H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87     H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 87/100 'H3_v1_87': {'dual_path': [128, 64], 'layers': [256, 128, 64], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': False, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.6493 > 0.4706 at epoch 4			
Found new best macro-f1 0.7143 > 0.6493 at epoch 5			

Max patience 21/20 reached!
Loading model from epoch 5 with macro-f1 0.7143
              precision    recall  f1-score   support

           0      0.931     0.954     0.943      1910
           1      0.544     0.439     0.486       239

    accuracy                          0.897      2149
   macro avg      0.738     0.697     0.714      2149
weighted avg      0.888     0.897     0.892      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89     H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
88     H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86     H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
90     H3_v1_86  0.680296  concat      [128]            [64]          0        0.5   True      True  selu   0.005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85     H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87     H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
91     H3_v1_87  0.714344  concat  [128, 64]  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 88/100 'H3_v1_88': {'dual_path': None, 'layers': [64], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': False, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5467 > 0.0000 at epoch 1			
Found new best macro-f1 0.5942 > 0.5467 at epoch 2			
Found new best macro-f1 0.6363 > 0.5942 at epoch 3			
Found new best macro-f1 0.6459 > 0.6363 at epoch 4			
Found new best macro-f1 0.6752 > 0.6459 at epoch 5			
Found new best macro-f1 0.6992 > 0.6752 at epoch 14			

Max patience 21/20 reached!
Loading model from epoch 14 with macro-f1 0.6992
              precision    recall  f1-score   support

           0      0.927     0.955     0.941      1910
           1      0.530     0.402     0.457       239

    accuracy                          0.894      2149
   macro avg      0.729     0.679     0.699      2149
weighted avg      0.883     0.894     0.887      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89     H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
88     H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86     H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
90     H3_v1_86  0.680296  concat      [128]            [64]          0        0.5   True      True  selu   0.005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85     H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
92     H3_v1_88  0.699175  concat       None            [64]        0.3        0.3  False      True  relu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87     H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
91     H3_v1_87  0.714344  concat  [128, 64]  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 89/100 'H3_v1_89': {'dual_path': [128, 64], 'layers': [128, 32], 'input_drop': 0.3, 'other_drop': 0, 'bn': False, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6145 > 0.0000 at epoch 1			
Found new best macro-f1 0.6165 > 0.6145 at epoch 3			
Found new best macro-f1 0.6197 > 0.6165 at epoch 5			
Found new best macro-f1 0.6357 > 0.6197 at epoch 7			
Found new best macro-f1 0.6757 > 0.6357 at epoch 9			

Max patience 21/20 reached!
Loading model from epoch 9 with macro-f1 0.6757
              precision    recall  f1-score   support

           0      0.922     0.956     0.939      1910
           1      0.500     0.351     0.413       239

    accuracy                          0.889      2149
   macro avg      0.711     0.654     0.676      2149
weighted avg      0.875     0.889     0.880      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89     H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
88     H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86     H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
93     H3_v1_89  0.675676  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
90     H3_v1_86  0.680296  concat      [128]            [64]          0        0.5   True      True  selu   0.005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85     H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
92     H3_v1_88  0.699175  concat       None            [64]        0.3        0.3  False      True  relu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87     H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
91     H3_v1_87  0.714344  concat  [128, 64]  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 90/100 'H3_v1_90': {'dual_path': [128], 'layers': [64], 'input_drop': 0.3, 'other_drop': 0.5, 'bn': False, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5099 > 0.4706 at epoch 2			
Found new best macro-f1 0.6019 > 0.5099 at epoch 3			
Found new best macro-f1 0.6022 > 0.6019 at epoch 7			
Found new best macro-f1 0.6083 > 0.6022 at epoch 9			
Found new best macro-f1 0.6129 > 0.6083 at epoch 10			
Found new best macro-f1 0.6198 > 0.6129 at epoch 11			
Found new best macro-f1 0.6590 > 0.6198 at epoch 13			
Found new best macro-f1 0.6947 > 0.6590 at epoch 18			
Found new best macro-f1 0.6959 > 0.6947 at epoch 28			

Max patience 21/20 reached!
Loading model from epoch 28 with macro-f1 0.6959
              precision    recall  f1-score   support

           0      0.926     0.956     0.941      1910
           1      0.528     0.393     0.451       239

    accuracy                          0.893      2149
   macro avg      0.727     0.675     0.696      2149
weighted avg      0.882     0.893     0.886      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89     H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
88     H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86     H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
93     H3_v1_89  0.675676  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
90     H3_v1_86  0.680296  concat      [128]            [64]          0        0.5   True      True  selu   0.005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85     H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
94     H3_v1_90  0.695917  concat      [128]            [64]        0.3        0.5  False      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
92     H3_v1_88  0.699175  concat       None            [64]        0.3        0.3  False      True  relu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87     H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
91     H3_v1_87  0.714344  concat  [128, 64]  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 91/100 'H3_v1_91': {'dual_path': [128, 64], 'layers': [256, 128, 64], 'input_drop': 0, 'other_drop': 0.5, 'bn': False, 'bn_inputs': True, 'activ': 'tanh', 'eta': 0.0005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5278 > 0.4706 at epoch 3			
Found new best macro-f1 0.5731 > 0.5278 at epoch 4			
Found new best macro-f1 0.6061 > 0.5731 at epoch 5			
Found new best macro-f1 0.6116 > 0.6061 at epoch 6			
Found new best macro-f1 0.6223 > 0.6116 at epoch 7			
Found new best macro-f1 0.6255 > 0.6223 at epoch 8			
Found new best macro-f1 0.6338 > 0.6255 at epoch 9			
Found new best macro-f1 0.6441 > 0.6338 at epoch 10			
Found new best macro-f1 0.6503 > 0.6441 at epoch 11			
Found new best macro-f1 0.6509 > 0.6503 at epoch 14			
Found new best macro-f1 0.6540 > 0.6509 at epoch 16			
Found new best macro-f1 0.6573 > 0.6540 at epoch 17			
Found new best macro-f1 0.6647 > 0.6573 at epoch 18			
Found new best macro-f1 0.6656 > 0.6647 at epoch 19			
Found new best macro-f1 0.6675 > 0.6656 at epoch 23			

Max patience 21/20 reached!
Loading model from epoch 23 with macro-f1 0.6675
              precision    recall  f1-score   support

           0      0.919     0.960     0.939      1910
           1      0.503     0.326     0.396       239

    accuracy                          0.889      2149
   macro avg      0.711     0.643     0.667      2149
weighted avg      0.873     0.889     0.879      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89     H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
88     H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
95     H3_v1_91  0.667488  concat  [128, 64]  [256, 128, 64]          0        0.5  False      True  tanh  0.0005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86     H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
93     H3_v1_89  0.675676  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
90     H3_v1_86  0.680296  concat      [128]            [64]          0        0.5   True      True  selu   0.005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85     H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
94     H3_v1_90  0.695917  concat      [128]            [64]        0.3        0.5  False      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
92     H3_v1_88  0.699175  concat       None            [64]        0.3        0.3  False      True  relu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87     H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
91     H3_v1_87  0.714344  concat  [128, 64]  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 92/100 'H3_v1_92': {'dual_path': [128, 64], 'layers': [128, 32], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': False, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.005}
  Time left for grid search completion: 0.1 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5028 > 0.0000 at epoch 1			
Found new best macro-f1 0.5534 > 0.5028 at epoch 2			
Found new best macro-f1 0.5576 > 0.5534 at epoch 3			
Found new best macro-f1 0.5642 > 0.5576 at epoch 4			
Found new best macro-f1 0.6024 > 0.5642 at epoch 5			
Found new best macro-f1 0.6127 > 0.6024 at epoch 14			
Found new best macro-f1 0.6165 > 0.6127 at epoch 16			
Found new best macro-f1 0.6334 > 0.6165 at epoch 18			
Found new best macro-f1 0.6371 > 0.6334 at epoch 19			
Found new best macro-f1 0.6574 > 0.6371 at epoch 32			
Found new best macro-f1 0.6605 > 0.6574 at epoch 36			

Max patience 21/20 reached!
Loading model from epoch 36 with macro-f1 0.6605
              precision    recall  f1-score   support

           0      0.915     0.978     0.945      1910
           1      0.607     0.272     0.376       239

    accuracy                          0.899      2149
   macro avg      0.761     0.625     0.661      2149
weighted avg      0.881     0.899     0.882      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89     H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
88     H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
96     H3_v1_92  0.660533  concat  [128, 64]       [128, 32]        0.3        0.3  False      True  selu   0.005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
95     H3_v1_91  0.667488  concat  [128, 64]  [256, 128, 64]          0        0.5  False      True  tanh  0.0005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86     H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
93     H3_v1_89  0.675676  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
90     H3_v1_86  0.680296  concat      [128]            [64]          0        0.5   True      True  selu   0.005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85     H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
94     H3_v1_90  0.695917  concat      [128]            [64]        0.3        0.5  False      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
92     H3_v1_88  0.699175  concat       None            [64]        0.3        0.3  False      True  relu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87     H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
91     H3_v1_87  0.714344  concat  [128, 64]  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 93/100 'H3_v1_93': {'dual_path': [128], 'layers': [64], 'input_drop': 0.3, 'other_drop': 0.3, 'bn': True, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.005}
  Time left for grid search completion: 0.0 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6653 > 0.0000 at epoch 1			
Found new best macro-f1 0.6670 > 0.6653 at epoch 2			
Found new best macro-f1 0.6746 > 0.6670 at epoch 15			
Found new best macro-f1 0.6747 > 0.6746 at epoch 16			
Found new best macro-f1 0.6898 > 0.6747 at epoch 23			
Found new best macro-f1 0.7068 > 0.6898 at epoch 25			
Found new best macro-f1 0.7179 > 0.7068 at epoch 34			

Max patience 21/20 reached!
Loading model from epoch 34 with macro-f1 0.7179
              precision    recall  f1-score   support

           0      0.929     0.965     0.947      1910
           1      0.596     0.414     0.489       239

    accuracy                          0.904      2149
   macro avg      0.763     0.690     0.718      2149
weighted avg      0.892     0.904     0.896      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89     H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
88     H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
96     H3_v1_92  0.660533  concat  [128, 64]       [128, 32]        0.3        0.3  False      True  selu   0.005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
95     H3_v1_91  0.667488  concat  [128, 64]  [256, 128, 64]          0        0.5  False      True  tanh  0.0005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86     H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
93     H3_v1_89  0.675676  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
90     H3_v1_86  0.680296  concat      [128]            [64]          0        0.5   True      True  selu   0.005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85     H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
94     H3_v1_90  0.695917  concat      [128]            [64]        0.3        0.5  False      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
92     H3_v1_88  0.699175  concat       None            [64]        0.3        0.3  False      True  relu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87     H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
91     H3_v1_87  0.714344  concat  [128, 64]  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
97     H3_v1_93  0.717858  concat      [128]            [64]        0.3        0.3   True     False  tanh   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 94/100 'H3_v1_94': {'dual_path': None, 'layers': [128, 64], 'input_drop': 0.3, 'other_drop': 0, 'bn': True, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.005}
  Time left for grid search completion: 0.0 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6660 > 0.0000 at epoch 1			
Found new best macro-f1 0.6744 > 0.6660 at epoch 19			
Found new best macro-f1 0.6754 > 0.6744 at epoch 21			

Max patience 21/20 reached!
Loading model from epoch 21 with macro-f1 0.6754
              precision    recall  f1-score   support

           0      0.923     0.951     0.937      1910
           1      0.481     0.364     0.414       239

    accuracy                          0.886      2149
   macro avg      0.702     0.657     0.675      2149
weighted avg      0.874     0.886     0.878      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89     H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
88     H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
96     H3_v1_92  0.660533  concat  [128, 64]       [128, 32]        0.3        0.3  False      True  selu   0.005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
95     H3_v1_91  0.667488  concat  [128, 64]  [256, 128, 64]          0        0.5  False      True  tanh  0.0005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86     H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
98     H3_v1_94  0.675425  concat       None       [128, 64]        0.3          0   True     False  tanh   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
93     H3_v1_89  0.675676  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
90     H3_v1_86  0.680296  concat      [128]            [64]          0        0.5   True      True  selu   0.005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85     H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
94     H3_v1_90  0.695917  concat      [128]            [64]        0.3        0.5  False      True  relu   0.005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
92     H3_v1_88  0.699175  concat       None            [64]        0.3        0.3  False      True  relu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87     H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
91     H3_v1_87  0.714344  concat  [128, 64]  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
97     H3_v1_93  0.717858  concat      [128]            [64]        0.3        0.3   True     False  tanh   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 95/100 'H3_v1_95': {'dual_path': [128, 64], 'layers': [256, 128, 64], 'input_drop': 0.3, 'other_drop': 0, 'bn': False, 'bn_inputs': True, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.0 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.5577 > 0.4706 at epoch 2			
Found new best macro-f1 0.5728 > 0.5577 at epoch 3			
Found new best macro-f1 0.6024 > 0.5728 at epoch 4			
Found new best macro-f1 0.6354 > 0.6024 at epoch 5			
Found new best macro-f1 0.6357 > 0.6354 at epoch 8			
Found new best macro-f1 0.6385 > 0.6357 at epoch 9			
Found new best macro-f1 0.6392 > 0.6385 at epoch 10			
Found new best macro-f1 0.6429 > 0.6392 at epoch 29			
Found new best macro-f1 0.6472 > 0.6429 at epoch 32			
Found new best macro-f1 0.6570 > 0.6472 at epoch 37			
Found new best macro-f1 0.6576 > 0.6570 at epoch 51			
Found new best macro-f1 0.6632 > 0.6576 at epoch 52			
Found new best macro-f1 0.6784 > 0.6632 at epoch 55			
Found new best macro-f1 0.6859 > 0.6784 at epoch 58			
Found new best macro-f1 0.6885 > 0.6859 at epoch 69			
Found new best macro-f1 0.6961 > 0.6885 at epoch 73			

Max patience 21/20 reached!
Loading model from epoch 73 with macro-f1 0.6961
              precision    recall  f1-score   support

           0      0.925     0.961     0.943      1910
           1      0.548     0.381     0.449       239

    accuracy                          0.896      2149
   macro avg      0.737     0.671     0.696      2149
weighted avg      0.883     0.896     0.888      2149

Results so far:
          MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67     H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39     H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58     H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24     H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81     H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89     H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22     H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44     H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0   BaseLR_C6L2  0.642959  concat                                                                                
1   BaseLR_C4L1  0.647585  concat                                                                                
63     H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73     H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15     H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30     H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61     H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31     H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41     H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10     H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2     BaseNN_50  0.654365  concat                                                                                
69     H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28     H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47     H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5      H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3    BaseNN_150  0.657440  concat                                                                                
88     H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11     H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
96     H3_v1_92  0.660533  concat  [128, 64]       [128, 32]        0.3        0.3  False      True  selu   0.005
37     H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33     H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59     H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71     H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
95     H3_v1_91  0.667488  concat  [128, 64]  [256, 128, 64]          0        0.5  False      True  tanh  0.0005
74     H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86     H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20     H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42     H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8      H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26     H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79     H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
98     H3_v1_94  0.675425  concat       None       [128, 64]        0.3          0   True     False  tanh   0.005
50     H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
93     H3_v1_89  0.675676  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu   0.005
4    BaseNN_300  0.676349  concat                                                                                
66     H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78     H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17     H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36     H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21     H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32     H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
64     H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57     H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
90     H3_v1_86  0.680296  concat      [128]            [64]          0        0.5   True      True  selu   0.005
75     H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84     H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53     H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70     H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23     H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82     H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76     H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51     H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48     H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38     H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80     H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65     H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27     H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12     H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14     H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16     H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18     H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19     H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72     H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7      H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85     H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68     H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45     H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62     H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
94     H3_v1_90  0.695917  concat      [128]            [64]        0.3        0.5  False      True  relu   0.005
99     H3_v1_95  0.696050  concat  [128, 64]  [256, 128, 64]        0.3          0  False      True  selu  0.0005
6      H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13     H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77     H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
92     H3_v1_88  0.699175  concat       None            [64]        0.3        0.3  False      True  relu   0.005
49     H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60     H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40     H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34     H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46     H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52     H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87     H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9      H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29     H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35     H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54     H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55     H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83     H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
91     H3_v1_87  0.714344  concat  [128, 64]  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
97     H3_v1_93  0.717858  concat      [128]            [64]        0.3        0.3   True     False  tanh   0.005
25     H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43     H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56     H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 96/100 'H3_v1_96': {'dual_path': [128, 64], 'layers': [64], 'input_drop': 0, 'other_drop': 0, 'bn': False, 'bn_inputs': False, 'activ': 'relu', 'eta': 0.0005}
  Time left for grid search completion: 0.0 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4706 > 0.0000 at epoch 1			
Found new best macro-f1 0.4829 > 0.4706 at epoch 8			
Found new best macro-f1 0.5366 > 0.4829 at epoch 9			
Found new best macro-f1 0.5810 > 0.5366 at epoch 10			
Found new best macro-f1 0.6035 > 0.5810 at epoch 11			
Found new best macro-f1 0.6346 > 0.6035 at epoch 12			
Found new best macro-f1 0.6645 > 0.6346 at epoch 13			
Found new best macro-f1 0.6688 > 0.6645 at epoch 14			
Found new best macro-f1 0.6722 > 0.6688 at epoch 15			
Found new best macro-f1 0.6767 > 0.6722 at epoch 16			
Found new best macro-f1 0.6796 > 0.6767 at epoch 18			

Max patience 21/20 reached!
Loading model from epoch 18 with macro-f1 0.6796
              precision    recall  f1-score   support

           0      0.922     0.959     0.940      1910
           1      0.519     0.351     0.419       239

    accuracy                          0.892      2149
   macro avg      0.720     0.655     0.680      2149
weighted avg      0.877     0.892     0.882      2149

Results so far:
           MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67      H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39      H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58      H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24      H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
81      H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89      H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22      H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44      H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0    BaseLR_C6L2  0.642959  concat                                                                                
1    BaseLR_C4L1  0.647585  concat                                                                                
63      H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73      H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15      H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30      H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61      H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31      H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41      H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10      H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2      BaseNN_50  0.654365  concat                                                                                
69      H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28      H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47      H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5       H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3     BaseNN_150  0.657440  concat                                                                                
88      H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11      H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
96      H3_v1_92  0.660533  concat  [128, 64]       [128, 32]        0.3        0.3  False      True  selu   0.005
37      H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33      H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59      H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71      H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
95      H3_v1_91  0.667488  concat  [128, 64]  [256, 128, 64]          0        0.5  False      True  tanh  0.0005
74      H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86      H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20      H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42      H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8       H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26      H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79      H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
98      H3_v1_94  0.675425  concat       None       [128, 64]        0.3          0   True     False  tanh   0.005
50      H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
93      H3_v1_89  0.675676  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu   0.005
4     BaseNN_300  0.676349  concat                                                                                
66      H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78      H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17      H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36      H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21      H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32      H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
100     H3_v1_96  0.679582  concat  [128, 64]            [64]          0          0  False     False  relu  0.0005
64      H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57      H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
90      H3_v1_86  0.680296  concat      [128]            [64]          0        0.5   True      True  selu   0.005
75      H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84      H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53      H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70      H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23      H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82      H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76      H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51      H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48      H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38      H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80      H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65      H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27      H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12      H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14      H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16      H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18      H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19      H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72      H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7       H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85      H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68      H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45      H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62      H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
94      H3_v1_90  0.695917  concat      [128]            [64]        0.3        0.5  False      True  relu   0.005
99      H3_v1_95  0.696050  concat  [128, 64]  [256, 128, 64]        0.3          0  False      True  selu  0.0005
6       H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13      H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77      H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
92      H3_v1_88  0.699175  concat       None            [64]        0.3        0.3  False      True  relu   0.005
49      H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60      H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40      H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34      H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46      H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52      H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87      H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9       H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29      H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35      H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54      H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55      H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83      H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
91      H3_v1_87  0.714344  concat  [128, 64]  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
97      H3_v1_93  0.717858  concat      [128]            [64]        0.3        0.3   True     False  tanh   0.005
25      H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43      H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56      H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 97/100 'H3_v1_97': {'dual_path': None, 'layers': [128, 32], 'input_drop': 0.3, 'other_drop': 0, 'bn': False, 'bn_inputs': False, 'activ': 'selu', 'eta': 0.0005}
  Time left for grid search completion: 0.0 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.5163 > 0.0000 at epoch 1			
Found new best macro-f1 0.5770 > 0.5163 at epoch 3			
Found new best macro-f1 0.5932 > 0.5770 at epoch 4			
Found new best macro-f1 0.6179 > 0.5932 at epoch 5			
Found new best macro-f1 0.6210 > 0.6179 at epoch 6			
Found new best macro-f1 0.6249 > 0.6210 at epoch 7			
Found new best macro-f1 0.6252 > 0.6249 at epoch 13			
Found new best macro-f1 0.6280 > 0.6252 at epoch 17			
Found new best macro-f1 0.6321 > 0.6280 at epoch 19			
Found new best macro-f1 0.6372 > 0.6321 at epoch 34			

Max patience 21/20 reached!
Loading model from epoch 34 with macro-f1 0.6372
              precision    recall  f1-score   support

           0      0.911     0.975     0.942      1910
           1      0.548     0.238     0.332       239

    accuracy                          0.893      2149
   macro avg      0.730     0.607     0.637      2149
weighted avg      0.871     0.893     0.874      2149

Results so far:
           MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67      H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39      H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58      H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24      H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
101     H3_v1_97  0.637230  concat       None       [128, 32]        0.3          0  False     False  selu  0.0005
81      H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89      H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22      H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44      H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0    BaseLR_C6L2  0.642959  concat                                                                                
1    BaseLR_C4L1  0.647585  concat                                                                                
63      H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73      H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15      H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30      H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61      H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31      H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41      H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10      H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2      BaseNN_50  0.654365  concat                                                                                
69      H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28      H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47      H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5       H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3     BaseNN_150  0.657440  concat                                                                                
88      H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11      H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
96      H3_v1_92  0.660533  concat  [128, 64]       [128, 32]        0.3        0.3  False      True  selu   0.005
37      H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33      H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59      H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71      H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
95      H3_v1_91  0.667488  concat  [128, 64]  [256, 128, 64]          0        0.5  False      True  tanh  0.0005
74      H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86      H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20      H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42      H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8       H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26      H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79      H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
98      H3_v1_94  0.675425  concat       None       [128, 64]        0.3          0   True     False  tanh   0.005
50      H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
93      H3_v1_89  0.675676  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu   0.005
4     BaseNN_300  0.676349  concat                                                                                
66      H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78      H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17      H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36      H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21      H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32      H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
100     H3_v1_96  0.679582  concat  [128, 64]            [64]          0          0  False     False  relu  0.0005
64      H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57      H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
90      H3_v1_86  0.680296  concat      [128]            [64]          0        0.5   True      True  selu   0.005
75      H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84      H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53      H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
70      H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23      H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82      H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76      H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51      H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48      H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38      H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80      H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65      H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27      H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12      H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14      H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16      H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18      H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19      H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72      H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7       H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85      H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68      H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45      H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62      H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
94      H3_v1_90  0.695917  concat      [128]            [64]        0.3        0.5  False      True  relu   0.005
99      H3_v1_95  0.696050  concat  [128, 64]  [256, 128, 64]        0.3          0  False      True  selu  0.0005
6       H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13      H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77      H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
92      H3_v1_88  0.699175  concat       None            [64]        0.3        0.3  False      True  relu   0.005
49      H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60      H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40      H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34      H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46      H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52      H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87      H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9       H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29      H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35      H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54      H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55      H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83      H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
91      H3_v1_87  0.714344  concat  [128, 64]  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
97      H3_v1_93  0.717858  concat      [128]            [64]        0.3        0.3   True     False  tanh   0.005
25      H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43      H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56      H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 98/100 'H3_v1_98': {'dual_path': None, 'layers': [128, 32], 'input_drop': 0, 'other_drop': 0, 'bn': True, 'bn_inputs': False, 'activ': 'tanh', 'eta': 0.005}
  Time left for grid search completion: 0.0 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.6828 > 0.0000 at epoch 1			

Max patience 21/20 reached!
Loading model from epoch 1 with macro-f1 0.6828
              precision    recall  f1-score   support

           0      0.942     0.883     0.912      1910
           1      0.378     0.569     0.454       239

    accuracy                          0.848      2149
   macro avg      0.660     0.726     0.683      2149
weighted avg      0.880     0.848     0.861      2149

Results so far:
           MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67      H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39      H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58      H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24      H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
101     H3_v1_97  0.637230  concat       None       [128, 32]        0.3          0  False     False  selu  0.0005
81      H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89      H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22      H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44      H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0    BaseLR_C6L2  0.642959  concat                                                                                
1    BaseLR_C4L1  0.647585  concat                                                                                
63      H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73      H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15      H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30      H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61      H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31      H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41      H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10      H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2      BaseNN_50  0.654365  concat                                                                                
69      H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28      H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47      H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5       H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3     BaseNN_150  0.657440  concat                                                                                
88      H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11      H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
96      H3_v1_92  0.660533  concat  [128, 64]       [128, 32]        0.3        0.3  False      True  selu   0.005
37      H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33      H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59      H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71      H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
95      H3_v1_91  0.667488  concat  [128, 64]  [256, 128, 64]          0        0.5  False      True  tanh  0.0005
74      H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86      H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20      H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42      H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8       H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26      H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79      H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
98      H3_v1_94  0.675425  concat       None       [128, 64]        0.3          0   True     False  tanh   0.005
50      H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
93      H3_v1_89  0.675676  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu   0.005
4     BaseNN_300  0.676349  concat                                                                                
66      H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78      H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17      H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36      H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21      H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32      H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
100     H3_v1_96  0.679582  concat  [128, 64]            [64]          0          0  False     False  relu  0.0005
64      H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57      H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
90      H3_v1_86  0.680296  concat      [128]            [64]          0        0.5   True      True  selu   0.005
75      H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84      H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53      H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
102     H3_v1_98  0.682844  concat       None       [128, 32]          0          0   True     False  tanh   0.005
70      H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23      H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82      H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76      H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51      H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48      H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38      H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80      H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65      H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27      H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12      H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14      H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16      H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18      H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19      H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72      H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7       H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
85      H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68      H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45      H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62      H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
94      H3_v1_90  0.695917  concat      [128]            [64]        0.3        0.5  False      True  relu   0.005
99      H3_v1_95  0.696050  concat  [128, 64]  [256, 128, 64]        0.3          0  False      True  selu  0.0005
6       H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13      H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77      H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
92      H3_v1_88  0.699175  concat       None            [64]        0.3        0.3  False      True  relu   0.005
49      H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60      H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40      H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34      H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46      H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52      H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87      H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9       H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29      H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35      H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54      H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55      H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83      H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
91      H3_v1_87  0.714344  concat  [128, 64]  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
97      H3_v1_93  0.717858  concat      [128]            [64]        0.3        0.3   True     False  tanh   0.005
25      H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43      H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56      H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 99/100 'H3_v1_99': {'dual_path': [128], 'layers': [128, 64], 'input_drop': 0.3, 'other_drop': 0, 'bn': True, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.0005}
  Time left for grid search completion: 0.0 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4819 > 0.0000 at epoch 1			
Found new best macro-f1 0.6034 > 0.4819 at epoch 2			
Found new best macro-f1 0.6422 > 0.6034 at epoch 3			
Found new best macro-f1 0.6458 > 0.6422 at epoch 4			
Found new best macro-f1 0.6490 > 0.6458 at epoch 12			
Found new best macro-f1 0.6607 > 0.6490 at epoch 14			
Found new best macro-f1 0.6665 > 0.6607 at epoch 15			
Found new best macro-f1 0.6675 > 0.6665 at epoch 17			
Found new best macro-f1 0.6833 > 0.6675 at epoch 20			
Found new best macro-f1 0.6916 > 0.6833 at epoch 23			

Max patience 21/20 reached!
Loading model from epoch 23 with macro-f1 0.6916
              precision    recall  f1-score   support

           0      0.929     0.942     0.935      1910
           1      0.476     0.423     0.448       239

    accuracy                          0.884      2149
   macro avg      0.703     0.682     0.692      2149
weighted avg      0.878     0.884     0.881      2149

Results so far:
           MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67      H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39      H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58      H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24      H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
101     H3_v1_97  0.637230  concat       None       [128, 32]        0.3          0  False     False  selu  0.0005
81      H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89      H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22      H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44      H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0    BaseLR_C6L2  0.642959  concat                                                                                
1    BaseLR_C4L1  0.647585  concat                                                                                
63      H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73      H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15      H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30      H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61      H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31      H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41      H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10      H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2      BaseNN_50  0.654365  concat                                                                                
69      H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28      H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47      H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5       H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3     BaseNN_150  0.657440  concat                                                                                
88      H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11      H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
96      H3_v1_92  0.660533  concat  [128, 64]       [128, 32]        0.3        0.3  False      True  selu   0.005
37      H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33      H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
59      H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71      H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
95      H3_v1_91  0.667488  concat  [128, 64]  [256, 128, 64]          0        0.5  False      True  tanh  0.0005
74      H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86      H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20      H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42      H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8       H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26      H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79      H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
98      H3_v1_94  0.675425  concat       None       [128, 64]        0.3          0   True     False  tanh   0.005
50      H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
93      H3_v1_89  0.675676  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu   0.005
4     BaseNN_300  0.676349  concat                                                                                
66      H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78      H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17      H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36      H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21      H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32      H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
100     H3_v1_96  0.679582  concat  [128, 64]            [64]          0          0  False     False  relu  0.0005
64      H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57      H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
90      H3_v1_86  0.680296  concat      [128]            [64]          0        0.5   True      True  selu   0.005
75      H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84      H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53      H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
102     H3_v1_98  0.682844  concat       None       [128, 32]          0          0   True     False  tanh   0.005
70      H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23      H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82      H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76      H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51      H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48      H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38      H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80      H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65      H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27      H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12      H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14      H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16      H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18      H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19      H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72      H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7       H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
103     H3_v1_99  0.691584  concat      [128]       [128, 64]        0.3          0   True      True  relu  0.0005
85      H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68      H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45      H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62      H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
94      H3_v1_90  0.695917  concat      [128]            [64]        0.3        0.5  False      True  relu   0.005
99      H3_v1_95  0.696050  concat  [128, 64]  [256, 128, 64]        0.3          0  False      True  selu  0.0005
6       H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13      H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77      H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
92      H3_v1_88  0.699175  concat       None            [64]        0.3        0.3  False      True  relu   0.005
49      H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60      H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40      H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34      H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46      H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52      H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87      H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9       H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29      H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35      H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54      H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55      H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83      H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
91      H3_v1_87  0.714344  concat  [128, 64]  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
97      H3_v1_93  0.717858  concat      [128]            [64]        0.3        0.3   True     False  tanh   0.005
25      H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43      H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56      H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005


======================================================================
Running grid search iteration 100/100 'H3_v1_100': {'dual_path': [128, 64], 'layers': [64], 'input_drop': 0, 'other_drop': 0, 'bn': False, 'bn_inputs': True, 'activ': 'relu', 'eta': 0.0005}
  Time left for grid search completion: 0.0 hrs
Training model TorchDeepNeuralClassifier
Found new best macro-f1 0.4763 > 0.0000 at epoch 1			
Found new best macro-f1 0.4788 > 0.4763 at epoch 6			
Found new best macro-f1 0.5443 > 0.4788 at epoch 7			
Found new best macro-f1 0.5880 > 0.5443 at epoch 8			
Found new best macro-f1 0.6354 > 0.5880 at epoch 9			
Found new best macro-f1 0.6544 > 0.6354 at epoch 11			
Found new best macro-f1 0.6578 > 0.6544 at epoch 12			
Found new best macro-f1 0.6656 > 0.6578 at epoch 15			

Max patience 21/20 reached!
Loading model from epoch 15 with macro-f1 0.6656
              precision    recall  f1-score   support

           0      0.922     0.942     0.932      1910
           1      0.442     0.364     0.399       239

    accuracy                          0.878      2149
   macro avg      0.682     0.653     0.666      2149
weighted avg      0.869     0.878     0.873      2149

Results so far:
           MODEL     SCORE    VECT  dual_path          layers input_drop other_drop     bn bn_inputs activ     eta
67      H3_v1_63  0.624023  concat       None       [128, 64]        0.3        0.3  False     False  tanh  0.0005
39      H3_v1_35  0.629538  concat      [128]       [128, 32]          0        0.5  False     False  selu   0.005
58      H3_v1_54  0.632102  concat      [128]            [64]        0.3        0.3  False     False  tanh  0.0005
24      H3_v1_20  0.635609  concat  [128, 64]       [128, 32]          0        0.5  False      True  selu   0.005
101     H3_v1_97  0.637230  concat       None       [128, 32]        0.3          0  False     False  selu  0.0005
81      H3_v1_77  0.639699  concat       None  [256, 128, 64]          0        0.5  False     False  tanh   0.005
89      H3_v1_85  0.639773  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  selu  0.0005
22      H3_v1_18  0.641367  concat  [128, 64]       [128, 32]          0        0.5  False     False  tanh  0.0005
44      H3_v1_40  0.641677  concat  [128, 64]  [256, 128, 64]        0.3        0.5  False      True  selu  0.0005
0    BaseLR_C6L2  0.642959  concat                                                                                
1    BaseLR_C4L1  0.647585  concat                                                                                
63      H3_v1_59  0.648207  concat       None       [128, 32]        0.3        0.5  False     False  tanh   0.005
73      H3_v1_69  0.649562  concat      [128]  [256, 128, 64]          0          0   True     False  tanh  0.0005
15      H3_v1_11  0.650696  concat  [128, 64]            [64]          0        0.3  False     False  tanh  0.0005
30      H3_v1_26  0.651666  concat      [128]  [256, 128, 64]        0.3        0.3  False      True  tanh  0.0005
61      H3_v1_57  0.652777  concat      [128]       [128, 32]          0          0  False     False  tanh  0.0005
31      H3_v1_27  0.652925  concat       None       [128, 32]          0        0.3  False     False  selu  0.0005
41      H3_v1_37  0.653429  concat  [128, 64]       [128, 32]          0        0.3   True     False  relu  0.0005
10      H3_v1_06  0.653559  concat      [128]            [64]          0        0.5  False     False  tanh  0.0005
2      BaseNN_50  0.654365  concat                                                                                
69      H3_v1_65  0.654631  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  tanh  0.0005
28      H3_v1_24  0.655086  concat      [128]  [256, 128, 64]          0          0  False      True  selu   0.005
47      H3_v1_43  0.656181  concat  [128, 64]            [64]          0        0.5  False     False  tanh   0.005
5       H3_v1_01  0.656841  concat      [128]       [128, 64]          0          0  False     False  selu  0.0005
3     BaseNN_150  0.657440  concat                                                                                
88      H3_v1_84  0.657480  concat  [128, 64]       [128, 64]          0        0.3  False     False  selu   0.005
11      H3_v1_07  0.658094  concat       None       [128, 64]          0          0  False     False  selu  0.0005
96      H3_v1_92  0.660533  concat  [128, 64]       [128, 32]        0.3        0.3  False      True  selu   0.005
37      H3_v1_33  0.661450  concat       None  [256, 128, 64]          0        0.3   True      True  selu  0.0005
33      H3_v1_29  0.665130  concat  [128, 64]       [128, 64]          0        0.3  False      True  selu  0.0005
104    H3_v1_100  0.665621  concat  [128, 64]            [64]          0          0  False      True  relu  0.0005
59      H3_v1_55  0.666954  concat       None       [128, 32]          0        0.5   True      True  tanh  0.0005
71      H3_v1_67  0.667090  concat       None       [128, 32]        0.3          0  False     False  tanh   0.005
95      H3_v1_91  0.667488  concat  [128, 64]  [256, 128, 64]          0        0.5  False      True  tanh  0.0005
74      H3_v1_70  0.668813  concat  [128, 64]  [256, 128, 64]          0          0  False      True  tanh   0.005
86      H3_v1_82  0.670702  concat  [128, 64]       [128, 64]          0          0   True     False  relu  0.0005
20      H3_v1_16  0.671565  concat       None            [64]          0          0   True     False  selu   0.005
42      H3_v1_38  0.671566  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu  0.0005
8       H3_v1_04  0.671709  concat  [128, 64]       [128, 32]          0        0.5   True     False  selu   0.005
26      H3_v1_22  0.673005  concat       None            [64]        0.3          0   True     False  selu  0.0005
79      H3_v1_75  0.674664  concat      [128]       [128, 32]        0.3          0  False      True  relu   0.005
98      H3_v1_94  0.675425  concat       None       [128, 64]        0.3          0   True     False  tanh   0.005
50      H3_v1_46  0.675644  concat  [128, 64]            [64]          0          0  False      True  selu   0.005
93      H3_v1_89  0.675676  concat  [128, 64]       [128, 32]        0.3          0  False      True  selu   0.005
4     BaseNN_300  0.676349  concat                                                                                
66      H3_v1_62  0.676683  concat      [128]  [256, 128, 64]          0          0   True      True  selu   0.005
78      H3_v1_74  0.676831  concat       None       [128, 32]          0        0.5  False      True  relu  0.0005
17      H3_v1_13  0.677096  concat       None            [64]          0        0.5   True     False  relu   0.005
36      H3_v1_32  0.677936  concat       None            [64]          0        0.5  False      True  selu   0.005
21      H3_v1_17  0.678064  concat       None       [128, 32]        0.3        0.3   True      True  tanh  0.0005
32      H3_v1_28  0.678141  concat       None            [64]          0          0   True     False  relu  0.0005
100     H3_v1_96  0.679582  concat  [128, 64]            [64]          0          0  False     False  relu  0.0005
64      H3_v1_60  0.679859  concat  [128, 64]       [128, 64]        0.3        0.3   True     False  tanh  0.0005
57      H3_v1_53  0.680247  concat      [128]            [64]        0.3          0   True     False  tanh  0.0005
90      H3_v1_86  0.680296  concat      [128]            [64]          0        0.5   True      True  selu   0.005
75      H3_v1_71  0.680376  concat  [128, 64]       [128, 64]          0        0.5  False     False  relu   0.005
84      H3_v1_80  0.680486  concat       None       [128, 64]          0        0.5   True      True  tanh  0.0005
53      H3_v1_49  0.682506  concat      [128]            [64]          0        0.3   True     False  selu   0.005
102     H3_v1_98  0.682844  concat       None       [128, 32]          0          0   True     False  tanh   0.005
70      H3_v1_66  0.683074  concat  [128, 64]       [128, 32]          0          0   True     False  selu   0.005
23      H3_v1_19  0.683883  concat  [128, 64]       [128, 64]          0        0.3  False      True  relu   0.005
82      H3_v1_78  0.683952  concat      [128]       [128, 64]          0        0.3  False     False  relu  0.0005
76      H3_v1_72  0.684069  concat      [128]       [128, 64]          0          0   True     False  tanh   0.005
51      H3_v1_47  0.684114  concat  [128, 64]       [128, 64]        0.3          0  False     False  relu   0.005
48      H3_v1_44  0.684666  concat      [128]       [128, 64]        0.3        0.5   True      True  selu   0.005
38      H3_v1_34  0.684771  concat  [128, 64]            [64]        0.3          0  False     False  tanh   0.005
80      H3_v1_76  0.685166  concat  [128, 64]            [64]        0.3        0.5   True      True  selu   0.005
65      H3_v1_61  0.685586  concat       None       [128, 32]          0        0.3   True     False  tanh   0.005
27      H3_v1_23  0.685949  concat  [128, 64]  [256, 128, 64]          0        0.3  False     False  relu   0.005
12      H3_v1_08  0.688280  concat      [128]  [256, 128, 64]        0.3        0.5   True      True  selu   0.005
14      H3_v1_10  0.688830  concat      [128]  [256, 128, 64]          0        0.3  False     False  relu   0.005
16      H3_v1_12  0.688895  concat  [128, 64]       [128, 64]          0          0  False     False  relu   0.005
18      H3_v1_14  0.689183  concat       None            [64]        0.3        0.5   True      True  selu  0.0005
19      H3_v1_15  0.689689  concat       None       [128, 32]          0        0.5  False      True  relu   0.005
72      H3_v1_68  0.690880  concat       None       [128, 32]        0.3        0.5   True      True  selu  0.0005
7       H3_v1_03  0.691182  concat      [128]       [128, 64]          0        0.5   True      True  selu   0.005
103     H3_v1_99  0.691584  concat      [128]       [128, 64]        0.3          0   True      True  relu  0.0005
85      H3_v1_81  0.691716  concat  [128, 64]       [128, 64]          0        0.5   True      True  selu  0.0005
68      H3_v1_64  0.693808  concat      [128]            [64]        0.3        0.5   True     False  tanh   0.005
45      H3_v1_41  0.694061  concat  [128, 64]            [64]          0        0.5   True      True  relu   0.005
62      H3_v1_58  0.694379  concat  [128, 64]       [128, 32]        0.3        0.5   True      True  selu  0.0005
94      H3_v1_90  0.695917  concat      [128]            [64]        0.3        0.5  False      True  relu   0.005
99      H3_v1_95  0.696050  concat  [128, 64]  [256, 128, 64]        0.3          0  False      True  selu  0.0005
6       H3_v1_02  0.696236  concat  [128, 64]       [128, 64]          0        0.5   True      True  tanh  0.0005
13      H3_v1_09  0.696435  concat      [128]            [64]        0.3        0.3   True      True  selu   0.005
77      H3_v1_73  0.697212  concat       None       [128, 64]        0.3        0.5  False      True  relu  0.0005
92      H3_v1_88  0.699175  concat       None            [64]        0.3        0.3  False      True  relu   0.005
49      H3_v1_45  0.700878  concat      [128]       [128, 32]        0.3          0   True     False  selu  0.0005
60      H3_v1_56  0.701702  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  selu  0.0005
40      H3_v1_36  0.701766  concat  [128, 64]       [128, 32]          0        0.5   True      True  relu  0.0005
34      H3_v1_30  0.702427  concat      [128]       [128, 64]          0        0.3   True      True  relu   0.005
46      H3_v1_42  0.703764  concat      [128]  [256, 128, 64]        0.3        0.5  False     False  relu  0.0005
52      H3_v1_48  0.705261  concat  [128, 64]  [256, 128, 64]        0.3        0.5   True      True  relu   0.005
87      H3_v1_83  0.705406  concat      [128]  [256, 128, 64]        0.3        0.5   True     False  tanh   0.005
9       H3_v1_05  0.706241  concat  [128, 64]       [128, 64]        0.3        0.3  False      True  relu  0.0005
29      H3_v1_25  0.706330  concat       None  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
35      H3_v1_31  0.706800  concat      [128]            [64]        0.3          0   True      True  selu   0.005
54      H3_v1_50  0.709670  concat  [128, 64]       [128, 32]        0.3          0   True      True  tanh  0.0005
55      H3_v1_51  0.711152  concat       None  [256, 128, 64]          0        0.3  False     False  relu   0.005
83      H3_v1_79  0.711972  concat      [128]  [256, 128, 64]          0        0.3  False      True  relu  0.0005
91      H3_v1_87  0.714344  concat  [128, 64]  [256, 128, 64]        0.3        0.3  False      True  relu   0.005
97      H3_v1_93  0.717858  concat      [128]            [64]        0.3        0.3   True     False  tanh   0.005
25      H3_v1_21  0.728202  concat       None       [128, 32]        0.3        0.3  False     False  relu   0.005
43      H3_v1_39  0.730170  concat      [128]  [256, 128, 64]        0.3        0.3  False     False  tanh   0.005
56      H3_v1_52  0.736901  concat      [128]  [256, 128, 64]        0.3        0.3   True      True  relu   0.005
